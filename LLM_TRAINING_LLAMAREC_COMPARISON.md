# So sÃ¡nh LLM Training vá»›i LlamaRec

## ğŸ“š LlamaRec Training Approach

### 1. **Training Objective** âœ…
- **Next-token prediction** (giá»‘ng LLM chuáº©n)
- **Label = index letter cá»§a ground-truth item**
  - VÃ­ dá»¥: Ground truth = item (D) â†’ Label token = "D"
- **Loss function**: Cross-entropy loss trÃªn token label
  - `L = -log P(token = GT_letter)`
- **Chá»‰ tÃ­nh loss á»Ÿ pháº§n Response** (token index + EOS)
  - KhÃ´ng tÃ­nh loss cho: instruction, user history, candidate list

---

## ğŸ” Kiá»ƒm tra Implementation hiá»‡n táº¡i

### 1. **Training Objective** âœ… ÄÃšNG

**Location**: `rerank/models/llm.py:149-241`

**Code**:
```python
# âœ… Sá»­ dá»¥ng SFTTrainer vá»›i next-token prediction
trainer = SFTTrainer(
    model=self.model,
    tokenizer=self.tokenizer,
    train_dataset=hf_train_dataset,
    args=training_args,
)

# âœ… Use train_on_responses_only to automatically mask prompt tokens
trainer = train_on_responses_only(
    trainer,
    instruction_part="<|im_start|>user\n",
    response_part="<|im_start|>assistant\n",
)
```

**Káº¿t luáº­n**: âœ… **ÄÃšNG** - Sá»­ dá»¥ng next-token prediction vÃ  mask prompt tokens

---

### 2. **Label Format** âŒ SAI

**LlamaRec**: Label = **letter index** (A, B, C, D, ...)

**Implementation hiá»‡n táº¡i**: Label = **number index** (1, 2, 3, 4, ...)

**Location**: 
- `rerank/methods/qwen_reranker_unified.py:702`
- `scripts/train_rerank_standalone.py:254`

**Code hiá»‡n táº¡i**:
```python
# âŒ SAI: DÃ¹ng number index
target = str(sample["target_idx"] + 1)  # "1", "2", "3", ...
```

**Code LlamaRec (Ä‘Ãºng)**:
```python
# âœ… ÄÃšNG: DÃ¹ng letter index
label = LETTERS[label_idx]  # "A", "B", "C", "D", ...
```

**Váº¥n Ä‘á»**:
- Numbers (1, 2, 3, ...) cÃ³ thá»ƒ xuáº¥t hiá»‡n trong item text/description
- Dá»… gÃ¢y confusion khi model predict
- Letter index (A, B, C, ...) Ã­t xuáº¥t hiá»‡n trong item text, trÃ¡nh confusion

---

### 3. **Loss Function** âœ… ÄÃšNG

**Location**: `rerank/models/llm.py:232-236`

**Code**:
```python
# âœ… train_on_responses_only tá»± Ä‘á»™ng mask prompt tokens
trainer = train_on_responses_only(
    trainer,
    instruction_part="<|im_start|>user\n",
    response_part="<|im_start|>assistant\n",
)
```

**Káº¿t luáº­n**: âœ… **ÄÃšNG** - Chá»‰ tÃ­nh loss á»Ÿ pháº§n Response (assistant response)

---

### 4. **Prompt Format** âš ï¸ KHÃC

**LlamaRec**: 
- Prompt cÃ³ thá»ƒ dÃ¹ng letter labels (A, B, C, ...)
- Answer format: "Answer with only one letter (A-T)."

**Implementation hiá»‡n táº¡i**:
- Prompt dÃ¹ng number labels (1, 2, 3, ...)
- Answer format: "Answer with only one number (1-20)."

**Location**: `rerank/models/llm.py:17-57`

**Code hiá»‡n táº¡i**:
```python
# âš ï¸ DÃ¹ng numbers
cand_text = "\n".join([f"{i+1}. {c}" for i, c in enumerate(candidates)])
answer_format = f"Answer with only one number (1-{num_candidates})."
```

---

### 5. **Rerank/Inference** âš ï¸ KHÃC

**LlamaRec**: 
- Predict letter token (A, B, C, ...)
- Map letter â†’ candidate index

**Implementation hiá»‡n táº¡i**:
- Predict number token (1, 2, 3, ...)
- Map number â†’ candidate index

**Location**: `rerank/models/llm.py:266-369`

**Code hiá»‡n táº¡i**:
```python
# âš ï¸ TÃ¬m number tokens
for i in range(1, num_candidates + 1):
    num_str = str(i)
    token_id = self.tokenizer.convert_tokens_to_ids(num_str)
    # ...
```

---

## ğŸ“Š TÃ³m táº¯t so sÃ¡nh

| Aspect | LlamaRec | Implementation hiá»‡n táº¡i | Status |
|--------|----------|-------------------------|--------|
| **Training Objective** | Next-token prediction | âœ… Next-token prediction | âœ… ÄÃšNG |
| **Label Format** | Letter index (A, B, C, ...) | âŒ Number index (1, 2, 3, ...) | âŒ SAI |
| **Loss Function** | Cross-entropy on token label | âœ… Cross-entropy on token label | âœ… ÄÃšNG |
| **Loss Masking** | Chá»‰ tÃ­nh loss á»Ÿ Response | âœ… Chá»‰ tÃ­nh loss á»Ÿ Response | âœ… ÄÃšNG |
| **Prompt Format** | Letter labels (A-T) | âš ï¸ Number labels (1-20) | âš ï¸ KHÃC |
| **Rerank/Inference** | Predict letter token | âš ï¸ Predict number token | âš ï¸ KHÃC |

---

## ğŸ”§ Äá» xuáº¥t sá»­a

### Priority 1: Sá»­a Label Format tá»« Number â†’ Letter

**LÃ½ do**:
- LlamaRec dÃ¹ng letter Ä‘á»ƒ trÃ¡nh confusion vá»›i numbers trong item text
- Numbers (1, 2, 3, ...) cÃ³ thá»ƒ xuáº¥t hiá»‡n trong item descriptions
- Letter index (A, B, C, ...) Ã­t xuáº¥t hiá»‡n hÆ¡n, trÃ¡nh confusion

**Cáº§n sá»­a**:

1. **Training data preparation**:
   - `rerank/methods/qwen_reranker_unified.py:702`
   - `scripts/train_rerank_standalone.py:254`

2. **Prompt format**:
   - `rerank/models/llm.py:17-57` (build_prompt_from_candidates)

3. **Rerank/Inference**:
   - `rerank/models/llm.py:266-369` (predict_probs)

**Code Ä‘á» xuáº¥t**:
```python
# Thay vÃ¬:
target = str(sample["target_idx"] + 1)  # "1", "2", "3", ...

# NÃªn dÃ¹ng:
LETTERS = list(string.ascii_uppercase[:20])  # A-T
target = LETTERS[sample["target_idx"]]  # "A", "B", "C", ...
```

---

## âœ… Káº¿t luáº­n

**ÄÃ£ Ä‘Ãºng vá»›i LlamaRec**:
- âœ… Training objective: Next-token prediction
- âœ… Loss function: Cross-entropy on token label
- âœ… Loss masking: Chá»‰ tÃ­nh loss á»Ÿ Response

**ChÆ°a Ä‘Ãºng vá»›i LlamaRec**:
- âŒ Label format: DÃ¹ng number (1, 2, 3, ...) thay vÃ¬ letter (A, B, C, ...)
- âš ï¸ Prompt format: DÃ¹ng number labels thay vÃ¬ letter labels
- âš ï¸ Rerank/Inference: Predict number token thay vÃ¬ letter token

**Khuyáº¿n nghá»‹**: Sá»­a label format tá»« number â†’ letter Ä‘á»ƒ giá»‘ng LlamaRec vÃ  trÃ¡nh confusion vá»›i numbers trong item text.

