# Ph√¢n t√≠ch c√°ch VIP5 g·ªëc th·ª±c hi·ªán Rerank

## üìö Ngu·ªìn tham kh·∫£o

Repo g·ªëc: https://github.com/jeykigung/VIP5/tree/main/src

File tham kh·∫£o:
- `retrieval/vip5_temp/notebooks/evaluate_VIP5.ipynb` (Cell 17, 18, 20)
- `retrieval/vip5_temp/src/model.py` (method `generate_step`)

---

## üîç C√°ch VIP5 g·ªëc th·ª±c hi·ªán Rerank

### 1. **S·ª≠ d·ª•ng Beam Search Generation** ‚úÖ

**Code t·ª´ notebook (Cell 17, 20)**:
```python
# Generate top-K items s·ª≠ d·ª•ng beam search
beam_outputs = model.generate(
    input_ids=batch['input_ids'].to('cuda'), 
    whole_word_ids=batch['whole_word_ids'].to('cuda'), 
    category_ids=batch['category_ids'].to('cuda'), 
    vis_feats=batch['vis_feats'].to('cuda'), 
    task=batch["task"][0],
    max_length=50, 
    num_beams=20,                    # ‚úÖ Beam size = 20
    no_repeat_ngram_size=0, 
    num_return_sequences=20,          # ‚úÖ Return top-20 sequences
    early_stopping=True
)

# Decode generated sequences
generated_sents = model.tokenizer.batch_decode(beam_outputs, skip_special_tokens=True)
```

**ƒê·∫∑c ƒëi·ªÉm**:
- S·ª≠ d·ª•ng **beam search** ƒë·ªÉ generate top-K items
- `num_beams=20`: Beam size = 20
- `num_return_sequences=20`: Return top-20 sequences
- Model **generate** to√†n b·ªô sequence (kh√¥ng ch·ªâ t√≠nh logit)

### 2. **Scoring d·ª±a tr√™n Rank trong Beam Search** ‚úÖ

**Code t·ª´ notebook**:
```python
gt = {}
ui_scores = {}
for i, info in enumerate(all_info):
    gt[i] = [int(info['target_item'])]
    pred_dict = {}
    for j in range(len(info['gen_item_list'])):
        try:
            # ‚úÖ Score = negative rank (rank 1 -> score -1, rank 2 -> score -2, ...)
            pred_dict[int(info['gen_item_list'][j])] = -(j+1)
        except:
            pass
    ui_scores[i] = pred_dict

# Evaluate
evaluate_all(ui_scores, gt, 5)
evaluate_all(ui_scores, gt, 10)
```

**ƒê·∫∑c ƒëi·ªÉm**:
- **KH√îNG t√≠nh logit tr·ª±c ti·∫øp**
- Score = **negative rank** trong beam search results
  - Item ƒë·∫ßu ti√™n (rank 1) ‚Üí score = -1
  - Item th·ª© 2 (rank 2) ‚Üí score = -2
  - ...
  - Item th·ª© 20 (rank 20) ‚Üí score = -20
- Score c√†ng cao (√≠t √¢m h∆°n) = rank c√†ng cao = item c√†ng t·ªët

### 3. **Direct Task (B-5) cho Reranking** ‚úÖ

**T·ª´ `data.py` (line 452-471)**:
```python
# Direct Task template B-5
template = "Which item of the following to recommend for user_{} ? \n {}"

# Source text: ch·ª©a T·∫§T C·∫¢ candidates v·ªõi visual token placeholders
candidates_with_visual = ' {}, '.format('<extra_id_0> ' * image_feature_size_ratio).join(candidate_samples) + ' <extra_id_0>' * image_feature_size_ratio
source_text = template.format(user_id, candidates_with_visual)

# Target text: ch·ªâ item target
target_text = f"item_{target_item}"
```

**ƒê·∫∑c ƒëi·ªÉm**:
- Prompt ch·ª©a **T·∫§T C·∫¢ candidates** trong m·ªôt prompt
- Visual features cho T·∫§T C·∫¢ candidates
- Model generate **m·ªôt item** t·ª´ danh s√°ch candidates

---

## ‚ö†Ô∏è So s√°nh v·ªõi Implementation hi·ªán t·∫°i

### Implementation hi·ªán t·∫°i (SAI) ‚ùå

**Location**: `rerank/methods/vip5_reranker.py:519-685`

**C√°ch l√†m**:
1. Encode prompt v·ªõi T·∫§T C·∫¢ candidates (‚úÖ ƒê√∫ng)
2. Decode t·ª´ng candidate ri√™ng l·∫ª ƒë·ªÉ t√≠nh logit (‚ùå SAI)
3. Score = logit c·ªßa item_id token (‚ùå SAI)

**Code hi·ªán t·∫°i**:
```python
# ‚ùå SAI: Decode t·ª´ng candidate ri√™ng l·∫ª
decoder_input_texts = [f"item_{item_id}" for item_id in valid_candidates]
decoder_inputs_tokenized = self.tokenizer(...)
decoder_outputs = self.model.decoder(...)
logits = self.model.lm_head(decoder_hidden)

# ‚ùå SAI: L·∫•y logit tr·ª±c ti·∫øp
score = float(logits[i, first_token_idx, item_token_id].item())
```

**V·∫•n ƒë·ªÅ**:
- Kh√¥ng s·ª≠ d·ª•ng **beam search generation**
- T√≠nh logit tr·ª±c ti·∫øp (kh√¥ng ƒë√∫ng v·ªõi c√°ch VIP5 g·ªëc)
- Kh√¥ng generate sequence, ch·ªâ decode m·ªôt l·∫ßn

### C√°ch VIP5 g·ªëc (ƒê√öNG) ‚úÖ

**C√°ch l√†m**:
1. Encode prompt v·ªõi T·∫§T C·∫¢ candidates (‚úÖ ƒê√∫ng)
2. **Generate** top-K items s·ª≠ d·ª•ng **beam search** (‚úÖ ƒê√∫ng)
3. Score = **negative rank** trong beam search results (‚úÖ ƒê√∫ng)

**Code g·ªëc**:
```python
# ‚úÖ ƒê√öNG: Generate v·ªõi beam search
beam_outputs = model.generate(
    input_ids=input_ids,
    whole_word_ids=whole_word_ids,
    category_ids=category_ids,
    vis_feats=vis_feats,
    task="direct",
    max_length=50,
    num_beams=20,
    num_return_sequences=20,
    early_stopping=True
)

# ‚úÖ ƒê√öNG: Score = negative rank
for j in range(len(generated_items)):
    pred_dict[int(generated_items[j])] = -(j+1)
```

---

## üîß C√°ch s·ª≠a Implementation

### Option 1: S·ª≠a theo c√°ch VIP5 g·ªëc (Recommended) ‚úÖ

**S·ª≠a `rerank()` method**:
```python
def rerank(
    self,
    user_id: int,
    candidates: List[int],
    **kwargs: Any
) -> List[Tuple[int, float]]:
    """Rerank candidates s·ª≠ d·ª•ng VIP5 beam search generation (theo c√°ch g·ªëc)."""
    self._validate_fitted()
    
    if not candidates:
        return []
    
    # Get visual features for candidates
    valid_candidates = []
    candidate_visual = []
    for item_id in candidates:
        if item_id in self.item_id_to_idx:
            idx = self.item_id_to_idx[item_id]
            valid_candidates.append(item_id)
            candidate_visual.append(self.visual_embeddings[idx])
    
    if not valid_candidates:
        return []
    
    # Build prompt v·ªõi Direct Task template (B-5)
    visual_token_placeholder = " <extra_id_0>" * self.image_feature_size_ratio
    candidates_with_visual = visual_token_placeholder.join([f"item_{c}" for c in valid_candidates]) + visual_token_placeholder
    direct_prompt = f"Which item of the following to recommend for user_{user_id} ? \n {candidates_with_visual}"
    
    # Prepare visual features
    all_candidates_visual_tensor = torch.stack(candidate_visual)  # [num_candidates, feat_dim]
    
    # Prepare VIP5 input
    vip5_input = prepare_vip5_input(
        direct_prompt,
        all_candidates_visual_tensor,
        self.tokenizer,
        max_length=self.max_text_length,
        image_feature_size_ratio=self.image_feature_size_ratio,
    )
    
    # Move to device
    input_ids = vip5_input["input_ids"].to(self.device)
    whole_word_ids = vip5_input["whole_word_ids"].to(self.device)
    category_ids = vip5_input["category_ids"].to(self.device)
    vis_feats = vip5_input["vis_feats"].to(self.device)
    
    # ‚úÖ Generate v·ªõi beam search (theo c√°ch g·ªëc)
    self.model.eval()
    with torch.no_grad():
        # Generate top-K items
        num_beams = min(len(valid_candidates), 20)  # Beam size = min(num_candidates, 20)
        num_return_sequences = min(len(valid_candidates), self.top_k)  # Return top-K
        
        beam_outputs = self.model.generate(
            input_ids=input_ids,
            whole_word_ids=whole_word_ids,
            category_ids=category_ids,
            vis_feats=vis_feats,
            task="direct",
            max_length=64,  # gen_max_length from VIP5
            num_beams=num_beams,
            num_return_sequences=num_return_sequences,
            no_repeat_ngram_size=0,
            early_stopping=True,
        )
        
        # Decode generated sequences
        generated_sents = self.tokenizer.batch_decode(beam_outputs, skip_special_tokens=True)
    
    # ‚úÖ Score = negative rank (theo c√°ch g·ªëc)
    scores = []
    for rank, generated_text in enumerate(generated_sents):
        try:
            # Extract item_id from generated text (e.g., "item_123" -> 123)
            item_id = int(generated_text.replace("item_", "").strip())
            if item_id in valid_candidates:
                # Score = negative rank (rank 0 -> score -1, rank 1 -> score -2, ...)
                score = -(rank + 1)
                scores.append((item_id, score))
        except ValueError:
            # Skip invalid generated text
            continue
    
    # Sort by score descending (higher score = better rank)
    scores.sort(key=lambda x: x[1], reverse=True)
    
    # Fill missing candidates with worst scores
    missing_candidates = set(valid_candidates) - {item_id for item_id, _ in scores}
    for item_id in missing_candidates:
        scores.append((item_id, -len(valid_candidates) - 1))
    
    # Return top_k
    return scores[:self.top_k]
```

### Option 2: Hybrid Approach (N·∫øu beam search qu√° ch·∫≠m)

N·∫øu beam search qu√° ch·∫≠m v·ªõi nhi·ªÅu candidates, c√≥ th·ªÉ:
1. D√πng beam search cho top-K candidates (sau khi filter)
2. Ho·∫∑c d√πng greedy generation thay v√¨ beam search
3. Ho·∫∑c t√≠nh logit tr·ª±c ti·∫øp nh∆∞ng **ƒë√∫ng c√°ch** (sum logits cho t·∫•t c·∫£ tokens)

---

## üìä So s√°nh Performance

| Aspect | VIP5 G·ªëc | Implementation hi·ªán t·∫°i |
|--------|----------|------------------------|
| **Method** | Beam search generation | Direct logit calculation |
| **Scoring** | Negative rank | Logit value |
| **Speed** | Ch·∫≠m h∆°n (beam search) | Nhanh h∆°n (direct decode) |
| **Accuracy** | ‚úÖ ƒê√∫ng (theo paper) | ‚ùå C√≥ th·ªÉ sai |
| **Consistency** | ‚úÖ Gi·ªëng training | ‚ö†Ô∏è Kh√°c v·ªõi training |

---

## ‚úÖ K·∫øt lu·∫≠n

**VIP5 g·ªëc s·ª≠ d·ª•ng beam search generation ƒë·ªÉ rerank**, kh√¥ng ph·∫£i t√≠nh logit tr·ª±c ti·∫øp. 

**C√°ch ƒë√∫ng**:
1. Encode prompt v·ªõi T·∫§T C·∫¢ candidates
2. Generate top-K items s·ª≠ d·ª•ng **beam search**
3. Score = **negative rank** trong beam search results

**Implementation hi·ªán t·∫°i SAI** v√¨:
- Kh√¥ng s·ª≠ d·ª•ng beam search
- T√≠nh logit tr·ª±c ti·∫øp (kh√¥ng ƒë√∫ng v·ªõi c√°ch g·ªëc)
- Kh√¥ng generate sequence

**Khuy·∫øn ngh·ªã**: S·ª≠a `rerank()` method ƒë·ªÉ s·ª≠ d·ª•ng beam search generation nh∆∞ VIP5 g·ªëc.

