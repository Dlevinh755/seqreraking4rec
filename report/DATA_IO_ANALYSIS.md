# PhÃ¢n tÃ­ch Save/Load Data - ÄÃ¡nh giÃ¡ vÃ  Cáº£i thiá»‡n

## ğŸ” PhÃ¡t hiá»‡n Váº¥n Ä‘á»

### 1. **Code trÃ¹ng láº·p: Load CSV Dataset** âŒ CRITICAL

**Váº¥n Ä‘á»:**
- `dataset/base.py` cÃ³ code load CSV **2 Láº¦N GIá»NG Há»†T** (lines 65-107 vÃ  113-155)
- `scripts/train_retrieval.py` cÃ³ code load CSV tÆ°Æ¡ng tá»± (lines 117-164)
- `evaluation/utils.py` Ä‘Ã£ cÃ³ `load_dataset_from_csv()` nhÆ°ng **KHÃ”NG Ä‘Æ°á»£c dÃ¹ng** trong `dataset/base.py`

**Impact:**
- ~100 lines code trÃ¹ng láº·p
- KhÃ³ maintain - sá»­a bug pháº£i sá»­a nhiá»u chá»—
- Inconsistent behavior

**Äá» xuáº¥t:**
- Refactor `dataset/base.py` Ä‘á»ƒ dÃ¹ng `evaluation.utils.load_dataset_from_csv()`
- Hoáº·c táº¡o `dataset/utils.py` vá»›i hÃ m chung

---

### 2. **Hardcoded Paths** âŒ CRITICAL

**Váº¥n Ä‘á»:**
- `scripts/train_rerank.py`:
  - Line 112: `Path("data/preprocessed/beauty_min_rating3-min_uc20-min_sc20/dataset_single_export.csv")`
  - Line 142: `Path("experiments/retrieval/lrurec/beauty/seed42/retrieved.csv")`
- `rerank/train_qwen.py`:
  - Line 106, 125, 130, 134: Hardcoded paths vá»›i `beauty_min_rating3-min_uc20-min_sc20`

**Impact:**
- KhÃ´ng flexible - chá»‰ cháº¡y Ä‘Æ°á»£c vá»›i dataset/seed cá»¥ thá»ƒ
- KhÃ³ test vá»›i datasets khÃ¡c
- KhÃ´ng dÃ¹ng config

**Äá» xuáº¥t:**
- Táº¡o utility functions Ä‘á»ƒ get paths tá»« config
- Sá»­ dá»¥ng `dataset._get_preprocessed_folder_path()` vÃ  `EXPERIMENT_ROOT`

---

### 3. **Inconsistent Data Flow** âš ï¸

**Data Flow hiá»‡n táº¡i:**
```
1. data_prepare.py
   â†’ Save: dataset_single_export.csv
   â†’ Save: clip_embeddings.pt (optional)

2. dataset/base.py
   â†’ Load: dataset_single_export.csv (2 láº§n code giá»‘ng nhau!)
   â†’ Fallback: dataset.pkl (legacy)

3. scripts/train_retrieval.py
   â†’ Load: dataset_single_export.csv (code trÃ¹ng láº·p)
   â†’ Save: retrieved.csv, retrieved_metrics.json

4. scripts/train_rerank.py
   â†’ Load: dataset_single_export.csv (hardcoded path)
   â†’ Load: retrieved.csv (hardcoded path)
```

**Váº¥n Ä‘á»:**
- KhÃ´ng cÃ³ standard interface cho save/load
- Má»—i script tá»± implement load logic
- KhÃ´ng cÃ³ validation

---

### 4. **Missing Path Utilities** âš ï¸

**Thiáº¿u:**
- Utility Ä‘á»ƒ get experiment paths: `get_experiment_path(method, dataset, seed)`
- Utility Ä‘á»ƒ get retrieved CSV path
- Utility Ä‘á»ƒ save/load model checkpoints

**Hiá»‡n táº¡i:**
- Má»—i script tá»± build paths
- Code láº·p láº¡i: `Path(EXPERIMENT_ROOT) / "retrieval" / method / dataset / f"seed{seed}"`

---

### 5. **Error Handling khÃ´ng Ä‘áº§y Ä‘á»§** âš ï¸

**Váº¥n Ä‘á»:**
- Má»™t sá»‘ nÆ¡i check `exists()` nhÆ°ng khÃ´ng cÃ³ clear error message
- KhÃ´ng validate data format sau khi load
- KhÃ´ng cÃ³ fallback strategies

---

### 6. **File Format Inconsistency** âš ï¸

**Hiá»‡n táº¡i:**
- Dataset: CSV (primary), pickle (fallback)
- Retrieved: CSV + JSON
- CLIP embeddings: `.pt` (torch.save)
- Model checkpoints: KhÃ´ng rÃµ (cÃ³ thá»ƒ trong training scripts)

**Váº¥n Ä‘á»:**
- KhÃ´ng cÃ³ documentation vá» format
- KhÃ´ng cÃ³ schema validation

---

## ğŸ“Š TÃ³m táº¯t Váº¥n Ä‘á»

### Critical Issues:
1. âŒ Code trÃ¹ng láº·p load CSV (3 nÆ¡i, ~100 lines)
2. âŒ Hardcoded paths trong training scripts
3. âŒ `dataset/base.py` cÃ³ code giá»‘ng nhau 2 láº§n

### Important Issues:
4. âš ï¸ KhÃ´ng cÃ³ path utilities
5. âš ï¸ Inconsistent error handling
6. âš ï¸ KhÃ´ng cÃ³ data validation

---

## ğŸ¯ Äá» xuáº¥t Cáº£i thiá»‡n

### Priority 1 (Critical):

1. **Refactor `dataset/base.py`**
   - Gá»™p 2 Ä‘oáº¡n code load CSV thÃ nh 1 hÃ m
   - DÃ¹ng `evaluation.utils.load_dataset_from_csv()` hoáº·c táº¡o `dataset/utils.py`

2. **Fix Hardcoded Paths**
   - `scripts/train_rerank.py`: DÃ¹ng config vÃ  utility functions
   - `rerank/train_qwen.py`: DÃ¹ng config (hoáº·c deprecate)

3. **Táº¡o Path Utilities**
   - `dataset/paths.py` hoáº·c `config.py` vá»›i helper functions
   - `get_experiment_path()`, `get_retrieved_csv_path()`, etc.

### Priority 2 (Important):

4. **Táº¡o Data I/O Utilities**
   - `dataset/io.py` vá»›i functions:
     - `save_dataset_csv()`
     - `load_dataset_csv()`
     - `validate_dataset_format()`

5. **Improve Error Handling**
   - Clear error messages
   - Validation after load
   - Fallback strategies

6. **Documentation**
   - Document data formats
   - Document save/load flow
   - Create data schema

---

## ğŸ’¾ Data Flow Äá» xuáº¥t (Sau cáº£i thiá»‡n)

```
1. data_prepare.py
   â†’ dataset.io.save_dataset_csv()  # Standardized save
   â†’ dataset.io.save_clip_embeddings()  # If needed

2. dataset/base.py
   â†’ dataset.io.load_dataset_csv()  # Single function, no duplication

3. scripts/train_retrieval.py
   â†’ dataset.io.load_dataset_csv()  # Reuse utility
   â†’ dataset.io.save_retrieved_csv()  # Standardized save

4. scripts/train_rerank.py
   â†’ dataset.io.load_dataset_csv()  # From config, not hardcoded
   â†’ dataset.io.load_retrieved_csv()  # From config, not hardcoded
```

---

## ğŸ“ Implementation Plan

### Step 1: Táº¡o Path Utilities
```python
# dataset/paths.py hoáº·c config.py
def get_preprocessed_csv_path(dataset_code, min_rating, min_uc, min_sc):
    ...

def get_experiment_path(stage, method, dataset_code, seed):
    ...

def get_retrieved_csv_path(method, dataset_code, seed):
    ...
```

### Step 2: Refactor dataset/base.py
- Extract CSV loading logic thÃ nh helper function
- DÃ¹ng helper function á»Ÿ cáº£ 2 chá»—

### Step 3: Fix Hardcoded Paths
- Update `scripts/train_rerank.py`
- Update `rerank/train_qwen.py` (hoáº·c deprecate)

### Step 4: Táº¡o I/O Utilities
- `dataset/io.py` vá»›i standardized save/load functions

---

**Status**: âš ï¸ Cáº§n cáº£i thiá»‡n ngay

