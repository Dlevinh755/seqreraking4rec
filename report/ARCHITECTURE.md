# Architecture Overview

## ğŸ“ Cáº¥u trÃºc Tá»•ng quan

Project Ä‘Æ°á»£c tá»• chá»©c theo **two-stage recommendation pipeline**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Stage 1:      â”‚
â”‚   Retrieval     â”‚  â†’  Top-K candidates
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Stage 2:      â”‚
â”‚   Reranking     â”‚  â†’  Final recommendations
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Cáº¥u trÃºc ThÆ° má»¥c

```
seqreraking4rec/
â”‚
â”œâ”€â”€ config.py                    # âš™ï¸ Main configuration (argparse)
â”œâ”€â”€ data_prepare.py              # ğŸš€ Data preprocessing script
â”‚
â”œâ”€â”€ dataset/                     # ğŸ“¦ Dataset modules
â”‚   â”œâ”€â”€ base.py                  # Abstract base class
â”‚   â”œâ”€â”€ beauty.py                # Amazon Beauty dataset
â”‚   â”œâ”€â”€ games.py                 # Video Games dataset
â”‚   â”œâ”€â”€ ml_100k.py               # MovieLens dataset
â”‚   â”œâ”€â”€ clip_embeddings.py       # CLIP embedding extraction
â”‚   â””â”€â”€ utils.py                 # Utility functions
â”‚
â”œâ”€â”€ retrieval/                   # ğŸ” Stage 1: Retrieval
â”‚   â”œâ”€â”€ base.py                  # BaseRetriever interface
â”‚   â”œâ”€â”€ registry.py              # Method registry
â”‚   â”œâ”€â”€ models/                  # PyTorch models
â”‚   â”‚   â”œâ”€â”€ neural_lru.py       # NeuralLRURec model
â”‚   â”‚   â””â”€â”€ mmgcn.py             # MMGCN model
â”‚   â””â”€â”€ methods/                 # BaseRetriever wrappers
â”‚       â”œâ”€â”€ lrurec.py            # LRURecRetriever
â”‚       â””â”€â”€ mmgcn.py             # MMGCNRetriever
â”‚
â”œâ”€â”€ rerank/                       # ğŸ¯ Stage 2: Reranking
â”‚   â”œâ”€â”€ base.py                  # BaseReranker interface
â”‚   â”œâ”€â”€ registry.py              # Method registry
â”‚   â”œâ”€â”€ models/                  # LLM models
â”‚   â”‚   â””â”€â”€ llm.py               # LLMModel (Qwen)
â”‚   â””â”€â”€ methods/                 # BaseReranker wrappers
â”‚       â”œâ”€â”€ identity.py          # IdentityReranker
â”‚       â”œâ”€â”€ random_reranker.py   # RandomReranker
â”‚       â””â”€â”€ qwen_reranker.py     # QwenReranker
â”‚
â”œâ”€â”€ pipelines/                    # ğŸ”— Pipeline Integration
â”‚   â”œâ”€â”€ base.py                  # TwoStagePipeline + Config
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ evaluation/                   # ğŸ“Š Evaluation
â”‚   â”œâ”€â”€ metrics.py               # Metric functions (Recall@K, NDCG@K)
â”‚   â””â”€â”€ offline_eval.py          # Offline evaluation script
â”‚
â”œâ”€â”€ scripts/                      # ğŸš€ Training & Inference Scripts
â”‚   â”œâ”€â”€ train_retrieval.py      # Train Stage 1
â”‚   â”œâ”€â”€ train_rerank.py          # Train Stage 2
â”‚   â””â”€â”€ train_pipeline.py        # Train end-to-end
â”‚
â”œâ”€â”€ tools/                        # ğŸ› ï¸ Utility Scripts
â”‚   â”œâ”€â”€ clean_preprocessed.py   # Clean preprocessed data
â”‚   â”œâ”€â”€ inspect_pickle.py        # Inspect dataset
â”‚   â”œâ”€â”€ test_filtering.py        # Test filtering
â”‚   â””â”€â”€ test_download_images.py  # Test image download
â”‚
â”œâ”€â”€ notebooks/                    # ğŸ““ Jupyter Notebooks
â”‚   â””â”€â”€ check.ipynb
â”‚
â”œâ”€â”€ experiments/                  # ğŸ“ Experiment Results
â”‚   â”œâ”€â”€ retrieval/
â”‚   â”œâ”€â”€ rerank/
â”‚   â””â”€â”€ pipeline/
â”‚
â””â”€â”€ data/                         # ğŸ’¾ Data
    â”œâ”€â”€ beauty/                  # Raw data
    â””â”€â”€ preprocessed/            # Preprocessed data
```

---

## ğŸ”§ Core Components

### 1. **Base Interfaces**

#### `BaseRetriever` (`retrieval/base.py`)
```python
class BaseRetriever(ABC):
    def fit(train_data: Dict[int, List[int]], **kwargs)
    def retrieve(user_id: int, exclude_items: Set[int]) -> List[int]
```

#### `BaseReranker` (`rerank/base.py`)
```python
class BaseReranker(ABC):
    def fit(train_data: Dict[int, List[int]], **kwargs)
    def rerank(user_id: int, candidates: List[int]) -> List[Tuple[int, float]]
```

### 2. **Registry Pattern**

Methods Ä‘Æ°á»£c Ä‘Äƒng kÃ½ trong registry Ä‘á»ƒ dá»… dÃ ng thay Ä‘á»•i:

```python
# retrieval/registry.py
RETRIEVER_REGISTRY = {
    "lrurec": LRURecRetriever,
    "mmgcn": MMGCNRetriever,
}

# rerank/registry.py
RERANKER_REGISTRY = {
    "identity": IdentityReranker,
    "random": RandomReranker,
    "qwen": QwenReranker,
}
```

### 3. **TwoStagePipeline** (`pipelines/base.py`)

```python
pipeline = TwoStagePipeline(
    PipelineConfig(
        retrieval=RetrievalConfig(method="lrurec", top_k=200),
        rerank=RerankConfig(method="qwen", top_k=50)
    )
)

pipeline.fit(train_data)
recommendations = pipeline.recommend(user_id=1)
```

---

## ğŸ”„ Data Flow

### Training Flow:
```
1. data_prepare.py
   â†“
   dataset.pkl (train/val/test splits)
   â†“
2. scripts/train_retrieval.py
   â†“
   Trained retriever + retrieved candidates
   â†“
3. scripts/train_rerank.py
   â†“
   Trained reranker
   â†“
4. evaluation/offline_eval.py
   â†“
   Final metrics
```

### Inference Flow:
```
User ID
   â†“
TwoStagePipeline.recommend()
   â†“
Stage 1: retriever.retrieve() â†’ [candidate_ids]
   â†“
Stage 2: reranker.rerank() â†’ [(item_id, score)]
   â†“
Final recommendations
```

---

## ğŸ¯ Design Principles

### 1. **Separation of Concerns**
- **Models** (`models/`): PyTorch nn.Module implementations
- **Methods** (`methods/`): Interface wrappers (BaseRetriever/BaseReranker)
- **Scripts** (`scripts/`): Training and inference scripts

### 2. **Registry Pattern**
- Easy to add new methods
- Change methods via config, not code

### 3. **Modularity**
- Each stage is independent
- Can run Stage 1 only (retrieval-only mode)
- Can combine any retrieval + rerank method

### 4. **Extensibility**
- Add new retriever: Implement `BaseRetriever` â†’ Register
- Add new reranker: Implement `BaseReranker` â†’ Register

---

## ğŸ“š Key Files

### Configuration
- `config.py`: Main configuration (argparse arguments)

### Data Processing
- `data_prepare.py`: Preprocess datasets
- `dataset/`: Dataset implementations

### Models
- `retrieval/models/`: Neural LRU, MMGCN
- `rerank/models/`: Qwen LLM

### Methods
- `retrieval/methods/`: Retrieval wrappers
- `rerank/methods/`: Reranking wrappers

### Pipeline
- `pipelines/base.py`: TwoStagePipeline implementation

### Scripts
- `scripts/train_retrieval.py`: Train Stage 1
- `scripts/train_rerank.py`: Train Stage 2
- `scripts/train_pipeline.py`: Train end-to-end

### Evaluation
- `evaluation/metrics.py`: Metric functions
- `evaluation/offline_eval.py`: Evaluation script

---

## ğŸš€ Quick Start

### 1. Preprocess Data
```bash
python data_prepare.py --use_text --use_image
```

### 2. Train Retrieval
```bash
python scripts/train_retrieval.py
```

### 3. Train Rerank
```bash
python scripts/train_rerank.py
```

### 4. Train End-to-End
```bash
python scripts/train_pipeline.py \
    --retrieval_method lrurec \
    --rerank_method qwen
```

---

## ğŸ“ Notes

- All models implement standard interfaces for easy swapping
- Results are saved to `experiments/` directory
- Configuration is centralized in `config.py`
- Documentation is kept up-to-date in this file and `README.md`

