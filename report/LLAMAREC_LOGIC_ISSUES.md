# Váº¥n Ä‘á» Logic Training vÃ  Rerank so vá»›i LlamaRec

## ğŸ“Š Tá»•ng quan

Sau khi so sÃ¡nh chi tiáº¿t vá»›i LlamaRec, tÃ´i phÃ¡t hiá»‡n **logic code Ä‘Ã£ Ä‘Ãºng**, nhÆ°ng cÃ³ **1 váº¥n Ä‘á» tiá»m áº©n** vÃ  **1 váº¥n Ä‘á» hyperparameters**.

---

## âœ… Logic Ä‘Ã£ Ä‘Ãºng vá»›i LlamaRec

### **1. Training Data Preparation** âœ…

- âœ… DÃ¹ng **letter labels** (A, B, C, ...) thay vÃ¬ numbers
- âœ… Random split point
- âœ… Candidates = [target] + negatives (shuffled)
- âœ… Target index = 0-indexed

**Code**: `rerank/methods/qwen_reranker_unified.py:652-704`

---

### **2. Training Process** âœ…

- âœ… Next-token prediction
- âœ… Mask prompt tokens vá»›i `train_on_responses_only`
- âœ… Chat template format
- âœ… LoRA fine-tuning

**Code**: `rerank/models/llm.py:164-263`

---

### **3. Rerank/Inference** âœ…

- âœ… Extract logits: `logits[:, -1]`
- âœ… Extract letter token IDs (vá»›i fallback strategies)
- âœ… Softmax trÃªn letter tokens
- âœ… Map vá» candidate indices
- âœ… Sort by probability

**Code**: `rerank/models/llm.py:290-414`

---

### **4. Prompt Format** âœ…

- âœ… DÃ¹ng letter labels (A, B, C, ...)
- âœ… Answer format vá»›i letters
- âœ… Format giá»‘ng LlamaRec

**Code**: `rerank/models/llm.py:19-69`

---

## âš ï¸ Váº¥n Ä‘á» Logic PhÃ¡t hiá»‡n

### **1. Text-only mode cÃ³ thá»ƒ khÃ´ng train** ğŸ”´

**Váº¥n Ä‘á»**:

**Code** (`rerank/methods/qwen_reranker_unified.py:296-403`):
```python
train_data_for_llm = kwargs.get("train_data_for_llm")

# For caption/semantic_summary modes, prepare training data from item_meta
if self.mode in ["caption", "semantic_summary"] and train_data_for_llm is None:
    train_samples = self._prepare_training_samples(train_data)
    # ... prepare train_data_for_llm ...
    
if train_data_for_llm is not None:
    # Train vá»›i pre-prepared data
    self.llm_model = LLMModel(train_data=train_data_for_llm, ...)
    self.llm_model.train(...)
else:
    # âŒ Chá»‰ load model, KHÃ”NG TRAIN!
    self.llm_model = LLMModel(train_data=None, ...)
    self.llm_model.load_model(...)
```

**PhÃ¢n tÃ­ch**:
- âœ… `caption/semantic_summary` modes: Tá»± Ä‘á»™ng prepare training data náº¿u khÃ´ng cÃ³
- âŒ `text_only` mode: **KHÃ”NG tá»± Ä‘á»™ng prepare** â†’ náº¿u khÃ´ng cÃ³ `train_data_for_llm` tá»« kwargs â†’ **model khÃ´ng Ä‘Æ°á»£c train!**

**Giáº£i phÃ¡p**:
```python
# ThÃªm auto-prepare cho text_only mode
if self.mode == "text_only" and train_data_for_llm is None:
    train_samples = self._prepare_training_samples(train_data)
    if len(train_samples) > 0:
        # Convert to LLM training format vá»›i letter labels
        from rerank.models.llm import build_prompt_from_candidates, LETTERS
        train_data_for_llm = []
        for sample in train_samples:
            history = sample["history"]
            candidates = sample["candidates"]
            target_idx = sample["target_idx"]
            
            # Build prompt
            history_texts = [self.item_id2text.get(item_id, f"item_{item_id}") 
                           for item_id in history[-self.max_history:]]
            candidate_texts = [self.item_id2text.get(item_id, f"item_{item_id}") 
                             for item_id in candidates]
            
            prompt = build_prompt_from_candidates(
                history_texts,
                candidates,  # IDs for mapping
                self.item_id2text,
                max_candidates=self.max_candidates
            )
            
            # Use letter index (LlamaRec style)
            if target_idx >= len(LETTERS):
                raise ValueError(f"Target index {target_idx} exceeds max letters")
            target = LETTERS[target_idx]  # Letter (A, B, C, ...)
            
            train_data_for_llm.append({
                "messages": [
                    {"role": "user", "content": prompt},
                    {"role": "assistant", "content": target}
                ]
            })
```

---

### **2. Epochs quÃ¡ Ã­t (CRITICAL)** ğŸ”´

**Váº¥n Ä‘á»**:
- `rerank_epochs = 1` (default) â†’ quÃ¡ Ã­t Ä‘á»ƒ model há»c Ä‘Æ°á»£c pattern
- Vá»›i 1635 samples, batch_size=16, gradient_accumulation=2:
  - Steps per epoch = 1635 / 32 â‰ˆ 51 steps
  - Total steps = 51 Ã— 1 = **51 steps** (quÃ¡ Ã­t!)

**Giáº£i phÃ¡p**:
```python
# config.py
parser.add_argument('--rerank_epochs', type=int, default=5,  # âœ… TÄƒng tá»« 1 lÃªn 5
```

---

## ğŸ“Š So sÃ¡nh vá»›i LlamaRec

| Aspect | LlamaRec | Project hiá»‡n táº¡i | Status |
|--------|----------|------------------|--------|
| **Training Data Prep** | Letter labels | âœ… Letter labels | âœ… ÄÃšNG |
| **Training Process** | Next-token prediction | âœ… Next-token prediction | âœ… ÄÃšNG |
| **Loss Masking** | Mask prompt tokens | âœ… `train_on_responses_only` | âœ… ÄÃšNG |
| **Prompt Format** | Letter labels | âœ… Letter labels | âœ… ÄÃšNG |
| **Rerank Process** | Verbalizer approach | âœ… Verbalizer approach | âœ… ÄÃšNG |
| **Text-only Auto-prepare** | N/A | âŒ KhÃ´ng tá»± Ä‘á»™ng | âš ï¸ Váº¤N Äá»€ |
| **Epochs** | 3-10 epochs | âŒ 1 epoch (default) | âš ï¸ Váº¤N Äá»€ |

---

## ğŸ¯ Káº¿t luáº­n

### **Logic Code**: âœ… **ÄÃšNG vá»›i LlamaRec**

**Táº¥t cáº£ cÃ¡c aspects chÃ­nh Ä‘á»u Ä‘Ãºng**:
- âœ… Training data preparation
- âœ… Training process
- âœ… Rerank process
- âœ… Prompt format

### **Váº¥n Ä‘á»**:

1. **Text-only mode** cÃ³ thá»ƒ khÃ´ng train náº¿u khÃ´ng cÃ³ `train_data_for_llm` tá»« kwargs
2. **Epochs quÃ¡ Ã­t** (1 epoch) â†’ Model chÆ°a há»c Ä‘Æ°á»£c pattern

### **Recommendation**:

1. âœ… **TÄƒng epochs lÃªn 5-10** (CRITICAL)
2. âœ… **ThÃªm auto-prepare cho text_only mode** (náº¿u Ä‘ang dÃ¹ng text_only mode)
3. âœ… **Kiá»ƒm tra xem model cÃ³ Ä‘Æ°á»£c train khÃ´ng** (check training loss)

**Logic code Ä‘Ã£ Ä‘Ãºng, váº¥n Ä‘á» chÃ­nh lÃ  hyperparameters (epochs quÃ¡ Ã­t)!**

