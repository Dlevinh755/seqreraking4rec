# Ph√¢n t√≠ch c∆° ch·∫ø Rerank c·ªßa c√°c LLM Rerankers

## üìä T·ªïng quan

C√≥ 2 LLM rerankers trong project:
1. **QwenReranker** - Text-only LLM (Qwen3-0.6B)
2. **Qwen3VLReranker** - Multimodal LLM (Qwen3-VL-2B) v·ªõi 4 modes

## üîç C∆° ch·∫ø Rerank

### 1. QwenReranker (Text-only)

**Location**: `rerank/methods/qwen_reranker.py:108-178`

#### Quy tr√¨nh:

```python
def rerank(self, user_id: int, candidates: List[int]) -> List[Tuple[int, float]]:
    # 1. Truncate history xu·ªëng 5 items cu·ªëi c√πng
    history = self.user_history.get(user_id, [])
    history = history[-self.max_history:]  # max_history = 5
    
    # 2. Build prompt v·ªõi format:
    prompt = build_prompt_from_candidates(
        history,           # User history (5 items cu·ªëi)
        candidates,        # Candidate item IDs
        self.item_id2text, # Mapping item_id -> text
        max_candidates=self.max_candidates
    )
    
    # 3. Predict probabilities t·ª´ LLM
    probs = self.llm_model.predict_probs(prompt, num_candidates=len(candidates))
    
    # 4. Rank candidates theo probabilities
    ranked_items = rank_candidates(probs, candidates)
    
    # 5. Return top-K v·ªõi scores
    return [(item_id, score) for item_id in ranked_items[:self.top_k]]
```

#### Prompt Format:

```
You are a recommendation ranking assistant.

Choose exactly ONE item the user is most likely to interact with next.

User history:
- item_text_1
- item_text_2
- item_text_3
- item_text_4
- item_text_5

Candidate items:
1. candidate_text_1
2. candidate_text_2
3. candidate_text_3
...
N. candidate_text_N

Answer with only one number (1-N).
```

#### C√°ch Extract Probabilities:

**Location**: `rerank/models/llm.py:201-272`

```python
def predict_probs(self, prompt, num_candidates=None):
    # 1. Tokenize prompt
    inputs = self.tokenizer(prompt, return_tensors="pt").to(self.model.device)
    
    # 2. Forward pass
    with torch.no_grad():
        outputs = self.model(**inputs)
    
    # 3. L·∫•y logits c·ªßa token cu·ªëi c√πng (next token prediction)
    logits = outputs.logits[:, -1]  # [vocab_size]
    
    # 4. Extract token IDs cho c√°c s·ªë 1, 2, 3, ..., num_candidates
    number_tokens = []
    for i in range(1, num_candidates + 1):
        num_str = str(i)
        token_id = self.tokenizer.convert_tokens_to_ids(num_str)
        if token_id != self.tokenizer.unk_token_id:
            number_tokens.append((i, token_id))
    
    # 5. Extract probabilities cho number tokens
    token_ids = [tid for _, tid in number_tokens]
    probs = F.softmax(logits[:, token_ids], dim=-1)  # [1, num_tokens]
    
    # 6. Map v·ªÅ candidate indices (1-indexed)
    prob_array = np.zeros(num_candidates)
    for idx, (cand_num, token_id) in enumerate(number_tokens):
        if cand_num <= num_candidates:
            prob_array[cand_num - 1] = probs[0, idx].item()
    
    return prob_array  # [num_candidates]
```

**C∆° ch·∫ø**:
- Model ƒë∆∞·ª£c y√™u c·∫ßu output m·ªôt s·ªë (1-N) ƒë·ªÉ ch·ªçn candidate
- Extract logits c·ªßa token cu·ªëi c√πng (next token prediction)
- L·∫•y probabilities c·ªßa c√°c number tokens (1, 2, 3, ..., N)
- M·ªói probability t∆∞∆°ng ·ª©ng v·ªõi m·ªôt candidate

#### Ranking:

```python
def rank_candidates(probs, candidate_ids):
    # Sort theo probability gi·∫£m d·∫ßn
    ranked = sorted(
        zip(candidate_ids, probs),
        key=lambda x: x[1],
        reverse=True
    )
    return [cid for cid, _ in ranked]
```

---

### 2. Qwen3VLReranker (Multimodal)

**Location**: `rerank/methods/qwen3vl_reranker.py:154-220`

#### Quy tr√¨nh:

```python
def _rerank_internal(self, user_id: int, candidates: List[int], user_history=None):
    # 1. Truncate history xu·ªëng 5 items cu·ªëi c√πng
    history = history[-self.max_history:]  # max_history = 5
    
    # 2. Predict probabilities (t√πy mode)
    probs = self.qwen3vl_model.predict_probs(
        user_history=history,
        candidates=candidates,
        item_meta=self.item_meta,
        num_candidates=len(candidates)
    )
    
    # 3. Rank candidates
    ranked_items = rank_candidates(probs, candidates)
    
    # 4. Return v·ªõi scores
    return [(item_id, score) for item_id in ranked_items[:self.top_k]]
```

#### 4 Modes:

##### Mode 1: `raw_image`

**Location**: `rerank/models/qwen3vl.py:280-465`

```python
def _predict_probs_raw_image(self, user_history, candidates, item_meta, num_candidates):
    # 1. Load images v√† texts cho history items
    history_images = []
    history_texts = []
    for item_id in user_history:
        meta = item_meta.get(item_id, {})
        text = meta.get("text", f"item_{item_id}")
        image_path = meta.get("image_path")
        if image_path:
            img = Image.open(image_path).convert("RGB")
            img = resize_image_for_qwen3vl(img, max_size=448)
            history_images.append(img)
        else:
            history_images.append(None)
        history_texts.append(text)
    
    # 2. Load images v√† texts cho candidates
    candidate_images = []
    candidate_texts = []
    for item_id in candidates:
        meta = item_meta.get(item_id, {})
        text = meta.get("text", f"item_{item_id}")
        image_path = meta.get("image_path")
        if image_path:
            img = Image.open(image_path).convert("RGB")
            img = resize_image_for_qwen3vl(img, max_size=448)
            candidate_images.append(img)
        else:
            candidate_images.append(None)
        candidate_texts.append(text)
    
    # 3. Build messages v·ªõi images
    messages = []
    # History v·ªõi images
    for img, text in zip(history_images, history_texts):
        if img:
            messages.append({
                "role": "user",
                "content": [
                    {"type": "image", "image": img},
                    {"type": "text", "text": text}
                ]
            })
        else:
            messages.append({"role": "user", "content": text})
    
    # Candidates v·ªõi images
    cand_text = "\n".join([f"{i+1}. {c}" for i, c in enumerate(candidate_texts)])
    messages.append({
        "role": "user",
        "content": [
            {"type": "image", "image": img} for img in candidate_images if img
        ] + [{"type": "text", "text": f"Candidate items:\n{cand_text}\nAnswer with only one number (1-{num_candidates})."}]
    })
    
    # 4. Apply chat template v√† tokenize
    text = self.processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
    inputs = self.processor(
        text=text,
        images=[img for img in history_images + candidate_images if img],
        return_tensors="pt",
        padding=True
    ).to(self.device)
    
    # 5. Forward pass
    with torch.no_grad():
        outputs = self.model(**inputs)
    
    # 6. Extract logits v√† probabilities (gi·ªëng QwenReranker)
    logits = outputs.logits[:, -1]  # [vocab_size]
    # Extract number token probabilities...
    return prob_array
```

##### Mode 2: `caption`

**Location**: `rerank/models/qwen3vl.py:467-553`

```python
def _predict_probs_caption(self, user_history, candidates, item_meta, num_candidates):
    # 1. Build history text v·ªõi captions
    history_texts = []
    for item_id in user_history:
        meta = item_meta.get(item_id, {})
        text = meta.get("text", f"item_{item_id}")
        caption = meta.get("caption", "")
        if caption:
            history_texts.append(f"{text} (Image: {caption})")
        else:
            history_texts.append(text)
    
    # 2. Build candidate texts v·ªõi captions
    candidate_texts = []
    for item_id in candidates:
        meta = item_meta.get(item_id, {})
        text = meta.get("text", f"item_{item_id}")
        caption = meta.get("caption", "")
        if caption:
            candidate_texts.append(f"{text} (Image: {caption})")
        else:
            candidate_texts.append(text)
    
    # 3. Build prompt (text-only, kh√¥ng c√≥ images)
    prompt = self._build_rerank_prompt(history_texts, candidate_texts)
    
    # 4. Tokenize v√† predict (gi·ªëng QwenReranker)
    inputs = self.processor.tokenizer(prompt, return_tensors="pt").to(self.device)
    # ... extract probabilities
```

##### Mode 3: `semantic_summary`

**Location**: `rerank/models/qwen3vl.py:554-626`

```python
def _predict_probs_semantic_summary_vl(self, user_history, candidates, item_meta, num_candidates):
    # T∆∞∆°ng t·ª± caption mode nh∆∞ng d√πng semantic_summary thay v√¨ caption
    # Format: "{text} (Semantic: {semantic_summary})"
    # C√≥ th·ªÉ d√πng images n·∫øu c·∫ßn (t√πy implementation)
```

##### Mode 4: `semantic_summary_small`

**Location**: `rerank/models/qwen3vl.py:627-700`

```python
def _predict_probs_semantic_summary_text(self, user_history, candidates, item_meta, num_candidates):
    # Text-only mode v·ªõi semantic summaries
    # Format: "{text} (Semantic: {semantic_summary})"
    # Kh√¥ng d√πng images
```

#### Prompt Format (chung cho t·∫•t c·∫£ modes):

```
You are a recommendation ranking assistant.

Choose exactly ONE item the user is most likely to interact with next.

User history:
- history_item_1
- history_item_2
- history_item_3
- history_item_4
- history_item_5

Candidate items:
1. candidate_item_1
2. candidate_item_2
3. candidate_item_3
...
N. candidate_item_N

Answer with only one number (1-N).
```

**Kh√°c bi·ªát gi·ªØa modes**:
- `raw_image`: History v√† candidates c√≥ images trong messages
- `caption`: History v√† candidates c√≥ format `{text} (Image: {caption})`
- `semantic_summary`: History v√† candidates c√≥ format `{text} (Semantic: {semantic_summary})`
- `semantic_summary_small`: Gi·ªëng semantic_summary nh∆∞ng text-only

#### C√°ch Extract Probabilities:

T∆∞∆°ng t·ª± QwenReranker:
1. Forward pass ƒë·ªÉ l·∫•y logits
2. Extract logits c·ªßa token cu·ªëi c√πng
3. L·∫•y probabilities c·ªßa number tokens (1, 2, 3, ..., N)
4. Map v·ªÅ candidate indices

---

## üîë ƒêi·ªÉm quan tr·ªçng

### 1. Single-Token Output

- Model ƒë∆∞·ª£c y√™u c·∫ßu output **ch·ªâ m·ªôt s·ªë** (1-N) ƒë·ªÉ ch·ªçn candidate
- Kh√¥ng ph·∫£i ranking to√†n b·ªô candidates trong m·ªôt output
- Extract probabilities t·ª´ **next token prediction** (logits c·ªßa token cu·ªëi c√πng)

### 2. Number Tokens

- S·ª≠ d·ª•ng s·ªë (1, 2, 3, ..., N) thay v√¨ ch·ªØ c√°i (A, B, C, ...)
- H·ªó tr·ª£ nhi·ªÅu candidates h∆°n (kh√¥ng gi·ªõi h·∫°n ·ªü 20 nh∆∞ ch·ªØ c√°i)
- Extract token IDs cho c√°c s·ªë t·ª´ vocabulary

### 3. Probability Extraction

- L·∫•y logits c·ªßa token cu·ªëi c√πng: `logits = outputs.logits[:, -1]`
- Extract probabilities cho number tokens: `probs = F.softmax(logits[:, token_ids], dim=-1)`
- Map v·ªÅ candidate indices: `prob_array[cand_num - 1] = probs[0, idx].item()`

### 4. Ranking

- Sort candidates theo probability gi·∫£m d·∫ßn
- Return top-K items v·ªõi scores

### 5. History Truncation

- Ch·ªâ gi·ªØ l·∫°i **5 items cu·ªëi c√πng** trong history
- √Åp d·ª•ng cho c·∫£ QwenReranker v√† Qwen3VLReranker

---

## üìù So s√°nh

| Aspect | QwenReranker | Qwen3VLReranker |
|--------|--------------|-----------------|
| **Input** | Text only | Text + Images (t√πy mode) |
| **History** | 5 items cu·ªëi | 5 items cu·ªëi |
| **Prompt** | Text-only | Multimodal (t√πy mode) |
| **Extract Probs** | Number tokens | Number tokens |
| **Ranking** | Sort by prob | Sort by prob |
| **Modes** | 1 mode | 4 modes (raw_image, caption, semantic_summary, semantic_summary_small) |

---

## ‚ö†Ô∏è L∆∞u √Ω

1. **Tokenization**: Number tokens c√≥ th·ªÉ kh√¥ng t·ªìn t·∫°i trong vocabulary ‚Üí fallback v·ªÅ letters
2. **Image Processing**: Images ƒë∆∞·ª£c resize v·ªÅ 448px (max_size) ƒë·ªÉ ti·∫øt ki·ªám memory
3. **Batch Processing**: Hi·ªán t·∫°i process t·ª´ng user m·ªôt, kh√¥ng batch
4. **Max Candidates**: C√≥ th·ªÉ gi·ªõi h·∫°n s·ªë candidates qua `max_candidates` parameter

