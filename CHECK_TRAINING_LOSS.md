# H∆∞·ªõng d·∫´n Ki·ªÉm tra Training Loss

## üîç V·∫•n ƒë·ªÅ

**Tests pass nh∆∞ng recall th·∫•p (0.4)** ‚Üí C√≥ th·ªÉ training loss kh√¥ng gi·∫£m

---

## üìä C√°ch Ki·ªÉm tra Training Loss

### **1. Xem Training Logs**

Khi training, b·∫°n s·∫Ω th·∫•y logs nh∆∞:

```
[TRAINING] Step 1: loss=3.9123
[TRAINING] Step 2: loss=3.8456
[TRAINING] Step 3: loss=3.7891
...
```

**Expected behavior**:
- **Initial loss**: ~3.9 (random v·ªõi 50 candidates: -log(1/50) ‚âà 3.9)
- **Sau 1 epoch**: ~2.5-3.5 (n·∫øu h·ªçc ƒë∆∞·ª£c m·ªôt ch√∫t)
- **Sau 4 epochs**: ~1.5-2.5 (n·∫øu h·ªçc t·ªët)

**N·∫øu loss kh√¥ng gi·∫£m**:
- ‚ùå Model kh√¥ng h·ªçc ƒë∆∞·ª£c g√¨
- ‚ùå C√≥ v·∫•n ƒë·ªÅ v·ªõi training process

---

### **2. Ki·ªÉm tra Loss Progression**

**Good training**:
```
Step 1: loss=3.9123
Step 10: loss=3.5123
Step 20: loss=3.1234
Step 30: loss=2.7891
...
Step 100: loss=2.1234
Step 200: loss=1.7891
```

**Bad training (loss kh√¥ng gi·∫£m)**:
```
Step 1: loss=3.9123
Step 10: loss=3.9123
Step 20: loss=3.9123
Step 30: loss=3.9123
...
```

---

### **3. N·∫øu Loss kh√¥ng gi·∫£m**

**Nguy√™n nh√¢n c√≥ th·ªÉ**:

1. **Learning rate qu√° th·∫•p**:
   - Current: 1e-4
   - Th·ª≠: 2e-4, 5e-4

2. **Learning rate qu√° cao**:
   - Loss oscillate ho·∫∑c NaN
   - Th·ª≠: 5e-5

3. **Training data format sai**:
   - Check training data c√≥ ƒë√∫ng format kh√¥ng
   - Check target labels c√≥ ƒë√∫ng kh√¥ng

4. **Model kh√¥ng ƒë∆∞·ª£c train**:
   - Check model c√≥ ƒë∆∞·ª£c save/load kh√¥ng
   - Check model state (training vs eval mode)

---

## üîß Action Plan

### **Step 1: Ki·ªÉm tra Training Logs**

Khi ch·∫°y training, xem logs:
- Loss c√≥ gi·∫£m kh√¥ng?
- Loss c√≥ oscillate kh√¥ng?
- Loss c√≥ NaN kh√¥ng?

### **Step 2: N·∫øu Loss kh√¥ng gi·∫£m**

1. **TƒÉng learning rate**:
   ```python
   # config.py
   --rerank_lr 2e-4  # Ho·∫∑c 5e-4
   ```

2. **Ki·ªÉm tra training data**:
   ```python
   # Check training data format
   print(f"Training samples: {len(train_data_for_llm)}")
   print(f"Sample: {train_data_for_llm[0]}")
   ```

3. **Ki·ªÉm tra model state**:
   ```python
   # Sau training
   print(f"Model training mode: {model.training}")
   model.eval()  # ‚úÖ ƒê·∫£m b·∫£o eval mode cho inference
   ```

### **Step 3: N·∫øu Loss gi·∫£m nh∆∞ng Recall v·∫´n th·∫•p**

1. **Ki·ªÉm tra evaluation**:
   - GT items c√≥ trong candidates kh√¥ng?
   - Candidates c√≥ ƒë∆∞·ª£c shuffle kh√¥ng?

2. **Test v·ªõi nhi·ªÅu candidates**:
   - Model c√≥ th·ªÉ t·ªët v·ªõi √≠t candidates nh∆∞ng k√©m v·ªõi nhi·ªÅu candidates

3. **Ki·ªÉm tra model size**:
   - Qwen3-0.6B c√≥ th·ªÉ qu√° nh·ªè
   - Th·ª≠ model l·ªõn h∆°n: Qwen3-1.7B, Qwen3-4B

---

## ‚úÖ T√≥m t·∫Øt

**N·∫øu tests pass nh∆∞ng recall th·∫•p**:

1. ‚úÖ **Ki·ªÉm tra training loss c√≥ gi·∫£m kh√¥ng** (CRITICAL)
2. ‚úÖ **N·∫øu loss kh√¥ng gi·∫£m** ‚Üí TƒÉng learning rate ho·∫∑c ki·ªÉm tra training data
3. ‚úÖ **N·∫øu loss gi·∫£m nh∆∞ng recall th·∫•p** ‚Üí Ki·ªÉm tra evaluation setup ho·∫∑c model size

**Next step**: Ch·∫°y training l·∫°i v√† xem training logs ƒë·ªÉ ki·ªÉm tra loss c√≥ gi·∫£m kh√¥ng!

