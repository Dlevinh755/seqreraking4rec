# Kiá»ƒm tra: Training vÃ  Evaluation cÃ³ Ä‘ang Ä‘Æ°á»£c thá»±c hiá»‡n Ä‘Ãºng khÃ´ng?

## âœ… Training Process

### 1. **Data Preparation** (`_prepare_training_samples`)

**File**: `rerank/methods/qwen_reranker_unified.py:651-703`

**Quy trÃ¬nh**:
1. âœ… Láº·p qua `train_data` (user_id -> [item_ids])
2. âœ… Skip users cÃ³ < 2 items
3. âœ… Chá»n target item: `end_pos = random.randint(1, len(items) - 1)` hoáº·c `len(items) - 1`
4. âœ… History: `items[:end_pos]`
5. âœ… Target: `items[end_pos]`
6. âœ… Sample negatives: `num_negatives = rerank_eval_candidates - 1` (tá»« config)
7. âœ… Candidates: `[target_item] + negatives`, shuffle
8. âœ… Target index: `candidates.index(target_item)` (0-indexed)

**âœ… ÄÃºng**: 
- Target index lÃ  0-indexed
- Sá»‘ lÆ°á»£ng negatives láº¥y tá»« config
- Candidates Ä‘Æ°á»£c shuffle

### 2. **Training Data Format** (`_train_text_model`)

**File**: `rerank/methods/qwen_reranker_unified.py:720-800`

**Quy trÃ¬nh**:
1. âœ… Build prompt tá»« sample: `_build_training_prompt(sample)`
2. âœ… Convert target_idx â†’ letter: `LETTERS[target_idx]` (LlamaRec style)
3. âœ… Format messages:
   ```python
   {
       "messages": [
           {"role": "system", "content": "You are a recommendation ranking assistant."},
           {"role": "user", "content": prompt},
           {"role": "assistant", "content": target_letter}  # âœ… Letter (A, B, C, ...)
       ]
   }
   ```

**âœ… ÄÃºng**:
- Target lÃ  letter (A, B, C, ...) thay vÃ¬ number
- Messages format Ä‘Ãºng cho chat template
- Prompt cÃ³ letters cho candidates

### 3. **LLM Training** (`LLMModel.train()`)

**File**: `rerank/models/llm.py:162-254`

**Quy trÃ¬nh**:
1. âœ… Convert messages â†’ text: `apply_chat_template(messages, tokenize=False, add_generation_prompt=False)`
2. âœ… Format: `'\n<user_content><|im_end|>\n<|im_start|>assistant\n<response><|im_end|>\n'`
3. âœ… Use `train_on_responses_only`: Mask prompt tokens, chá»‰ tÃ­nh loss trÃªn response tokens
4. âœ… Training vá»›i SFTTrainer:
   - `num_epochs`: tá»« config (default: 1)
   - `batch_size`: tá»« config (default: 16)
   - `learning_rate`: tá»« config (default: 1e-4) âœ… ÄÃƒ Sá»¬A
   - `gradient_accumulation_steps`: 4
   - `fp16`: True
   - `optim`: "adamw_8bit"

**âœ… ÄÃºng**:
- Chat template format Ä‘Ãºng
- Loss chá»‰ tÃ­nh trÃªn response tokens (LlamaRec style)
- Hyperparameters láº¥y tá»« config
- Learning rate Ä‘Ã£ Ä‘Æ°á»£c sá»­a Ä‘á»ƒ láº¥y tá»« config

**âš ï¸ Váº¥n Ä‘á»**:
- `num_epochs=1` (default) â†’ quÃ¡ Ã­t, cáº§n tÄƒng lÃªn 10-20

### 4. **Training Loop vá»›i Validation**

**File**: `rerank/methods/qwen_reranker_unified.py:1300-1330`

**Quy trÃ¬nh**:
1. âœ… Láº·p qua epochs
2. âœ… Train model: `trainer.train()`
3. âœ… Validate: `_evaluate_split(val_data, k=min(10, self.top_k))`
4. âœ… Early stopping: náº¿u `epochs_no_improve >= patience`
5. âœ… Load best model: `trainer.model.load_state_dict(best_model_state)`

**âœ… ÄÃºng**:
- Validation sau má»—i epoch
- Early stopping hoáº¡t Ä‘á»™ng
- Best model Ä‘Æ°á»£c lÆ°u vÃ  load

## âœ… Evaluation Process

### 1. **Candidate Loading** (`_evaluate_split`)

**File**: `rerank/methods/qwen_reranker_unified.py:1332-1373`

**Quy trÃ¬nh**:
1. âœ… Load pre-generated candidates: `load_rerank_candidates()`
2. âœ… Láº¥y candidates cho user tá»« val/test split
3. âœ… Skip náº¿u khÃ´ng cÃ³ candidates

**âœ… ÄÃºng**:
- Sá»­ dá»¥ng pre-generated candidates (tá»« data_prepare.py)
- ÄÃºng split (val hoáº·c test)

### 2. **Reranking** (`rerank()`)

**File**: `rerank/methods/qwen_reranker_unified.py:425-649`

**Quy trÃ¬nh**:
1. âœ… Get user history: `history[-self.max_history:]` (truncate)
2. âœ… Build prompt: `build_prompt_from_candidates()` hoáº·c `_build_test_prompt_sample()`
3. âœ… Apply chat template: `apply_chat_template(messages, add_generation_prompt=True)` âœ… ÄÃƒ Sá»¬A
4. âœ… Predict probabilities: `predict_probs(prompt, num_candidates)`
5. âœ… Rank candidates: `rank_candidates(probs, candidates)`
6. âœ… Return top_k: `ranked_items[:self.top_k]`

**âœ… ÄÃºng**:
- History Ä‘Æ°á»£c truncate theo `max_history`
- Prompt dÃ¹ng letters (A, B, C, ...)
- Chat template format Ä‘Æ°á»£c sá»­ dá»¥ng cho inference âœ… ÄÃƒ Sá»¬A
- Probabilities Ä‘Æ°á»£c normalize

### 3. **Metric Calculation**

**File**: `rerank/methods/qwen_reranker_unified.py:1365-1373`

**Quy trÃ¬nh**:
1. âœ… Rerank candidates: `rerank(user_id, candidates)`
2. âœ… Get top_k items: `[item_id for item_id, _ in reranked[:k]]`
3. âœ… Calculate hits: `len(set(top_k_items) & set(gt_items))`
4. âœ… Calculate recall: `hits / len(gt_items)`
5. âœ… Average recall: `np.mean(recalls)`

**âœ… ÄÃºng**:
- Recall calculation Ä‘Ãºng
- Top-k items Ä‘Æ°á»£c láº¥y Ä‘Ãºng
- Average across users

## ğŸ” Kiá»ƒm tra chi tiáº¿t

### **Training Data Format**

**Expected**:
```python
{
    "messages": [
        {"role": "system", "content": "You are a recommendation ranking assistant."},
        {"role": "user", "content": "You are a recommendation ranking assistant.\n\nChoose exactly ONE item...\n\nCandidate items:\nA. item1\nB. item2\n...\n\nAnswer with only one letter (A-Z, a-z)."},
        {"role": "assistant", "content": "E"}  # âœ… Letter
    ]
}
```

**Actual**: âœ… ÄÃºng format

### **Inference Prompt Format**

**Expected** (sau chat template):
```
<|im_start|>user
You are a recommendation ranking assistant.
...
Answer with only one letter (A-Z, a-z).<|im_end|>
<|im_start|>assistant
```

**Actual**: âœ… ÄÃºng format (Ä‘Ã£ sá»­a)

### **Target Label Format**

**Expected**: Letter (A, B, C, ...) - LlamaRec style

**Actual**: âœ… `LETTERS[target_idx]` - ÄÃºng

### **Loss Calculation**

**Expected**: 
- Loss chá»‰ tÃ­nh trÃªn response tokens (letter + EOS)
- KhÃ´ng tÃ­nh loss cho prompt tokens

**Actual**: âœ… `train_on_responses_only` - ÄÃºng

## âš ï¸ Váº¥n Ä‘á» phÃ¡t hiá»‡n

### 1. **QuÃ¡ Ã­t Epochs** (CRITICAL)

**Váº¥n Ä‘á»**:
- Default `rerank_epochs=1` â†’ quÃ¡ Ã­t
- Model chÆ°a ká»‹p há»c

**Giáº£i phÃ¡p**:
```bash
--rerank_epochs 10  # Hoáº·c 20
```

### 2. **Learning Rate Ä‘Ã£ Ä‘Æ°á»£c sá»­a** âœ…

**TrÆ°á»›c**: Hardcode `learning_rate=2e-5`
**Sau**: Láº¥y tá»« config `rerank_lr=1e-4` âœ…

### 3. **Training Loss cao** (4.25)

**NguyÃªn nhÃ¢n**:
- QuÃ¡ Ã­t epochs (1)
- Model chÆ°a converge

**Giáº£i phÃ¡p**:
- TÄƒng epochs lÃªn 10-20
- Monitor training loss

## âœ… Káº¿t luáº­n

### **Training Process**: âœ… ÄÃšNG

1. âœ… Data preparation Ä‘Ãºng
2. âœ… Training data format Ä‘Ãºng (letters, chat template)
3. âœ… Loss calculation Ä‘Ãºng (chá»‰ trÃªn response tokens)
4. âœ… Training loop Ä‘Ãºng (vá»›i validation vÃ  early stopping)
5. âš ï¸ Cáº§n tÄƒng epochs (1 â†’ 10-20)

### **Evaluation Process**: âœ… ÄÃšNG

1. âœ… Candidate loading Ä‘Ãºng (pre-generated)
2. âœ… Prompt building Ä‘Ãºng (letters, chat template)
3. âœ… Reranking Ä‘Ãºng (predict_probs â†’ rank)
4. âœ… Metric calculation Ä‘Ãºng (Recall@K)

### **Cáº§n sá»­a**:

1. âœ… **ÄÃ£ sá»­a**: Learning rate láº¥y tá»« config
2. âš ï¸ **Cáº§n sá»­a**: TÄƒng `--rerank_epochs` lÃªn 10-20
3. âš ï¸ **Cáº§n monitor**: Training loss pháº£i giáº£m xuá»‘ng < 2.0

## ğŸ“ Recommendations

1. **TÄƒng epochs**: `--rerank_epochs 10` hoáº·c `20`
2. **Monitor training loss**: Pháº£i giáº£m tá»« 4.25 xuá»‘ng < 2.0
3. **Check validation recall**: Pháº£i tÄƒng dáº§n qua cÃ¡c epochs
4. **Verify predictions**: Kiá»ƒm tra xem model cÃ³ predict Ä‘Ãºng letter khÃ´ng

