# PhÃ¢n tÃ­ch táº¡i sao VIP5 cÃ³ Recall tháº¥p hÆ¡n BERT4Rec

## ğŸ” Váº¥n Ä‘á» phÃ¡t hiá»‡n

### 1. **CÃ¡ch tÃ­nh Score cá»§a VIP5 - KHÃ”NG ÄÃšNG** âŒ

**Location**: `rerank/methods/vip5_reranker.py:855` vÃ  `567`

```python
# VIP5 hiá»‡n táº¡i:
encoder_hidden = encoder_outputs.last_hidden_state  # [1, seq_len, d_model]
score = float(encoder_hidden.mean(dim=1).squeeze(0).norm().item())
```

**Váº¥n Ä‘á»**:
- VIP5 lÃ  má»™t **seq2seq model** (T5-based), nhÆ°ng chá»‰ dÃ¹ng **encoder output**
- Score Ä‘Æ°á»£c tÃ­nh báº±ng **norm cá»§a mean pooling** - khÃ´ng cÃ³ Ã½ nghÄ©a vá» máº·t recommendation
- KhÃ´ng sá»­ dá»¥ng **decoder** Ä‘á»ƒ predict probability cá»§a item_id
- Score nÃ y khÃ´ng pháº£n Ã¡nh kháº£ nÄƒng model predict item Ä‘Ã³

**So sÃ¡nh vá»›i BERT4Rec**:
```python
# BERT4Rec - ÄÃšNG:
scores = self.model.predict_scores(history_tensor, candidates_tensor)  # [1, num_candidates]
# predict_scores() tÃ­nh score thá»±c sá»± cho tá»«ng candidate dá»±a trÃªn model output
```

### 2. **CÃ´ng thá»©c Recall - CÃ³ thá»ƒ cáº£i thiá»‡n** âš ï¸

**VIP5**:
```python
recalls.append(hits / min(k, len(gt_items)))  # Line 868
```

**BERT4Rec**:
```python
recalls.append(hits / min(k, len(valid_gt_items)))  # Line 414
```

**Qwen3VL** (Ä‘Ã£ sá»­a):
```python
recalls.append(hits / len(gt_items))  # CÃ´ng thá»©c chuáº©n
```

**PhÃ¢n tÃ­ch**:
- Cáº£ VIP5 vÃ  BERT4Rec Ä‘á»u dÃ¹ng `min(k, len(gt_items))` - cÃ³ thá»ƒ khÃ´ng cáº§n thiáº¿t
- CÃ´ng thá»©c chuáº©n nÃªn lÃ : `hits / len(gt_items)`
- Tuy nhiÃªn, trong thá»±c táº¿ thÆ°á»ng `k >= len(gt_items)`, nÃªn khÃ´ng áº£nh hÆ°á»Ÿng nhiá»u

### 3. **CÃ¡ch Rerank - VIP5 cháº­m hÆ¡n** âš ï¸

**VIP5**:
- Encode **tá»«ng candidate má»™t cÃ¡ch riÃªng láº»** (loop qua tá»«ng item)
- Má»—i candidate cáº§n má»™t forward pass riÃªng
- Ráº¥t cháº­m vá»›i nhiá»u candidates

**BERT4Rec**:
- Batch processing: encode history má»™t láº§n, predict scores cho táº¥t cáº£ candidates cÃ¹ng lÃºc
- Nhanh hÆ¡n nhiá»u

### 4. **Training Process - CÃ³ thá»ƒ khÃ¡c biá»‡t** âš ï¸

Cáº§n kiá»ƒm tra:
- VIP5 training cÃ³ Ä‘Ãºng khÃ´ng?
- Loss function cÃ³ phÃ¹ há»£p khÃ´ng?
- Model cÃ³ converge khÃ´ng?

---

## ğŸ”§ Äá» xuáº¥t sá»­a

### Priority 1: Sá»­a cÃ¡ch tÃ­nh Score cá»§a VIP5

VIP5 nÃªn dÃ¹ng **decoder** Ä‘á»ƒ tÃ­nh score thá»±c sá»± cho item_id:

```python
# Thay vÃ¬:
score = float(encoder_hidden.mean(dim=1).squeeze(0).norm().item())

# NÃªn dÃ¹ng:
# Option 1: Generate vÃ  score
decoder_input_ids = tokenizer.encode(f"item_{item_id}", return_tensors="pt").to(device)
decoder_outputs = model.decoder(
    input_ids=decoder_input_ids,
    encoder_hidden_states=encoder_hidden,
    encoder_attention_mask=attention_mask,
    return_dict=True
)
logits = model.lm_head(decoder_outputs.last_hidden_state)  # [1, seq_len, vocab_size]
# Score = logit cá»§a item_id token

# Option 2: Direct prediction (náº¿u cÃ³ method)
score = model.predict_item_score(encoder_hidden, item_id)
```

### Priority 2: Sá»­a cÃ´ng thá»©c Recall

```python
# Thay vÃ¬:
recalls.append(hits / min(k, len(gt_items)))

# NÃªn dÃ¹ng:
recalls.append(hits / len(gt_items))  # CÃ´ng thá»©c chuáº©n
```

### Priority 3: Batch Processing (Optional)

CÃ³ thá»ƒ batch encode nhiá»u candidates cÃ¹ng lÃºc Ä‘á»ƒ tÄƒng tá»‘c, nhÆ°ng cáº§n Ä‘áº£m báº£o Ä‘Ãºng logic.

---

## ğŸ“Š So sÃ¡nh chi tiáº¿t

| Aspect | VIP5 | BERT4Rec |
|--------|------|----------|
| **Score Calculation** | âŒ Norm cá»§a encoder output (khÃ´ng Ä‘Ãºng) | âœ… predict_scores() method (Ä‘Ãºng) |
| **Decoder Usage** | âŒ KhÃ´ng dÃ¹ng | âœ… DÃ¹ng trong predict_scores() |
| **Batch Processing** | âŒ Loop tá»«ng candidate | âœ… Batch táº¥t cáº£ candidates |
| **Recall Formula** | âš ï¸ `hits / min(k, len(gt))` | âš ï¸ `hits / min(k, len(gt))` |
| **Speed** | âŒ Cháº­m (loop tá»«ng item) | âœ… Nhanh (batch) |
| **Model Type** | Seq2Seq (T5) | Encoder-only (BERT) |

---

## ğŸ¯ Káº¿t luáº­n

**NguyÃªn nhÃ¢n chÃ­nh**: VIP5 Ä‘ang dÃ¹ng cÃ¡ch tÃ­nh score **KHÃ”NG ÄÃšNG**:
- Chá»‰ dÃ¹ng encoder output
- TÃ­nh norm cá»§a mean pooling - khÃ´ng cÃ³ Ã½ nghÄ©a
- KhÃ´ng dÃ¹ng decoder Ä‘á»ƒ predict probability cá»§a item_id

**Giáº£i phÃ¡p**: ÄÃ£ sá»­a cÃ¡ch tÃ­nh score Ä‘á»ƒ dÃ¹ng decoder vÃ  tÃ­nh logit thá»±c sá»± cá»§a item_id token.

## âœ… ÄÃ£ sá»­a

1. **CÃ¡ch tÃ­nh Score**: 
   - TrÆ°á»›c: `score = encoder_hidden.mean().norm()` âŒ
   - Sau: DÃ¹ng decoder Ä‘á»ƒ predict `item_{item_id}`, láº¥y logit cá»§a item_id token âœ…

2. **Prompt Format**:
   - TrÆ°á»›c: Prompt cÃ³ cáº£ history + candidate âŒ
   - Sau: Prompt chá»‰ cÃ³ history (giá»‘ng training format) âœ…

3. **CÃ´ng thá»©c Recall**:
   - TrÆ°á»›c: `hits / min(k, len(gt_items))` âš ï¸
   - Sau: `hits / len(gt_items)` (cÃ´ng thá»©c chuáº©n) âœ…

**Ká»³ vá»ng**: Sau khi sá»­a, VIP5 recall sáº½ tÄƒng Ä‘Ã¡ng ká»ƒ vÃ  cÃ³ thá»ƒ ngang báº±ng hoáº·c cao hÆ¡n BERT4Rec.

