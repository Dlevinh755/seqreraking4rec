# Deep Debug: Táº¡i sao Recall tháº¥p dÃ¹ Tests Pass?

## ğŸ“Š TÃ¬nh huá»‘ng

**Debug tests Ä‘á»u PASS** nhÆ°ng **Recall@20 váº«n ~0.4** (gáº§n random)

**Tests passed**:
- âœ… Letter tokens Ä‘Æ°á»£c tÃ¬m tháº¥y
- âœ… Model prediction khÃ´ng uniform (std=0.34)
- âœ… Training data format Ä‘Ãºng
- âœ… Evaluation setup Ä‘Ãºng

**Váº¥n Ä‘á»**: Model cÃ³ thá»ƒ khÃ´ng Ä‘Æ°á»£c train Ä‘Ãºng hoáº·c khÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘Ãºng sau training.

---

## ğŸ” CÃ¡c Váº¥n Ä‘á» Tiá»m áº©n

### **1. Model khÃ´ng Ä‘Æ°á»£c Save/Load sau Training** ğŸ”´

**Váº¥n Ä‘á»**:
- Model Ä‘Æ°á»£c train nhÆ°ng khÃ´ng Ä‘Æ°á»£c save
- Hoáº·c model Ä‘Æ°á»£c save nhÆ°ng khÃ´ng Ä‘Æ°á»£c load láº¡i
- Inference dÃ¹ng model chÆ°a Ä‘Æ°á»£c train

**Kiá»ƒm tra**:
```python
# Trong fit() method
# Sau khi train, model cÃ³ Ä‘Æ°á»£c save khÃ´ng?
# Khi rerank(), model cÃ³ Ä‘Æ°á»£c load tá»« checkpoint khÃ´ng?
```

**Code hiá»‡n táº¡i** (`rerank/models/llm.py:228-246`):
```python
training_args = SFTConfig(
    output_dir="./qwen_rerank",
    save_steps=500,  # âœ… Save má»—i 500 steps
    load_best_model_at_end=False,  # âŒ KHÃ”NG load best model!
    ...
)
```

**Váº¥n Ä‘á»**:
- `load_best_model_at_end=False` â†’ Model khÃ´ng tá»± Ä‘á»™ng load best checkpoint
- Model sau training cÃ³ thá»ƒ khÃ´ng pháº£i lÃ  best model
- Cáº§n manually load checkpoint hoáº·c save final model

---

### **2. Training Loss khÃ´ng Ä‘Æ°á»£c Log Ä‘áº§y Ä‘á»§** ğŸŸ¡

**Váº¥n Ä‘á»**:
- `logging_steps=1` (Ä‘Ã£ sá»­a) nhÆ°ng cÃ³ thá»ƒ khÃ´ng Ä‘á»§
- Cáº§n kiá»ƒm tra loss cÃ³ giáº£m khÃ´ng

**CÃ¡ch kiá»ƒm tra**:
```python
# ThÃªm vÃ o training
training_args = SFTConfig(
    logging_steps=1,  # âœ… Log má»—i step
    report_to="tensorboard",  # Hoáº·c "wandb" Ä‘á»ƒ track loss
    ...
)
```

---

### **3. Model Ä‘Æ°á»£c Test trÃªn Sample Ä‘Æ¡n giáº£n** ğŸŸ¡

**Váº¥n Ä‘á»**:
- Debug script test trÃªn sample Ä‘Æ¡n giáº£n (5 candidates)
- Trong thá»±c táº¿ cÃ³ thá»ƒ cÃ³ 20-50 candidates
- Model cÃ³ thá»ƒ predict tá»‘t vá»›i Ã­t candidates nhÆ°ng kÃ©m vá»›i nhiá»u candidates

**Kiá»ƒm tra**:
```python
# Test vá»›i sá»‘ lÆ°á»£ng candidates giá»‘ng evaluation
probs = model.predict_probs(prompt, num_candidates=20)  # Hoáº·c 50
print(f"Std vá»›i 20 candidates: {np.std(probs)}")
# Náº¿u std giáº£m â†’ model kÃ©m vá»›i nhiá»u candidates
```

---

### **4. Training Data Quality** ğŸŸ¡

**Váº¥n Ä‘á»**:
- Training data cÃ³ thá»ƒ khÃ´ng Ä‘á»§ quality
- History quÃ¡ ngáº¯n
- Candidates khÃ´ng Ä‘a dáº¡ng

**Kiá»ƒm tra**:
```python
# Kiá»ƒm tra training data distribution
from collections import Counter
targets = [sample['messages'][2]['content'] for sample in train_data_for_llm]
target_counts = Counter(targets)
print(f"Target distribution: {target_counts}")

# Náº¿u quÃ¡ imbalanced â†’ cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng training
# VÃ­ dá»¥: 80% lÃ  "A", 20% lÃ  cÃ¡c letters khÃ¡c
```

---

### **5. Model Size cÃ³ thá»ƒ quÃ¡ nhá»** ğŸŸ¡

**Váº¥n Ä‘á»**:
- Qwen3-0.6B cÃ³ thá»ƒ quÃ¡ nhá» cho task nÃ y
- LlamaRec dÃ¹ng Llama 2-7B (lá»›n hÆ¡n 10x)

**So sÃ¡nh**:
- **LlamaRec**: Llama 2-7B (7B parameters)
- **Project hiá»‡n táº¡i**: Qwen3-0.6B (0.6B parameters)

**Giáº£i phÃ¡p**:
- Thá»­ model lá»›n hÆ¡n: Qwen3-1.7B, Qwen3-4B
- Hoáº·c tÄƒng LoRA rank: r=16, alpha=32

---

### **6. Evaluation Candidates khÃ¡c Training** ğŸ”´

**Váº¥n Ä‘á»**:
- Training: Candidates Ä‘Æ°á»£c sample tá»« all_items
- Evaluation: Candidates cÃ³ thá»ƒ tá»« pre-generated list
- Distribution khÃ¡c nhau â†’ model khÃ´ng generalize

**Kiá»ƒm tra**:
```python
# So sÃ¡nh training candidates vs evaluation candidates
# Training: random sample tá»« all_items
# Evaluation: pre-generated candidates (cÃ³ thá»ƒ cÃ³ bias)
```

---

## ğŸ”§ Debugging Steps

### **Step 1: Kiá»ƒm tra Model cÃ³ Ä‘Æ°á»£c Save/Load khÃ´ng**

```python
# ThÃªm vÃ o fit() sau training
print(f"[DEBUG] Model state after training:")
print(f"  Output dir: {training_args.output_dir}")
print(f"  Checkpoints saved: {os.listdir(training_args.output_dir) if os.path.exists(training_args.output_dir) else 'None'}")

# Kiá»ƒm tra xem model cÃ³ Ä‘Æ°á»£c load láº¡i khÃ´ng
print(f"[DEBUG] Model device: {self.model.device}")
print(f"[DEBUG] Model dtype: {self.model.dtype}")
```

---

### **Step 2: Kiá»ƒm tra Training Loss**

```python
# ThÃªm callback Ä‘á»ƒ track loss
from transformers import TrainerCallback

class LossCallback(TrainerCallback):
    def on_log(self, args, state, control, logs=None, **kwargs):
        if 'loss' in logs:
            print(f"Step {state.global_step}: loss={logs['loss']:.4f}")

# ThÃªm vÃ o trainer
trainer.add_callback(LossCallback())
```

---

### **Step 3: Test vá»›i sá»‘ lÆ°á»£ng Candidates giá»‘ng Evaluation**

```python
# Test vá»›i 20-50 candidates (giá»‘ng evaluation)
prompt = build_prompt_from_candidates(
    history,
    list(range(20)),  # 20 candidates
    item_id2text,
    max_candidates=20
)

probs = model.predict_probs(prompt, num_candidates=20)
print(f"Std vá»›i 20 candidates: {np.std(probs)}")
print(f"Max prob: {np.max(probs):.4f}, Min prob: {np.min(probs):.4f}")

# Náº¿u std < 0.1 vá»›i 20 candidates â†’ model kÃ©m vá»›i nhiá»u candidates
```

---

### **Step 4: Kiá»ƒm tra Training Data Distribution**

```python
# Kiá»ƒm tra target distribution
from collections import Counter
targets = [sample['messages'][2]['content'] for sample in train_data_for_llm]
target_counts = Counter(targets)

print(f"Target distribution:")
for letter, count in sorted(target_counts.items()):
    print(f"  {letter}: {count} ({count/len(targets)*100:.1f}%)")

# Náº¿u quÃ¡ imbalanced â†’ cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng training
```

---

### **Step 5: So sÃ¡nh Training vs Evaluation Candidates**

```python
# Kiá»ƒm tra distribution cá»§a candidates
# Training: random sample
# Evaluation: pre-generated

# Training candidates
train_candidates = [sample['candidates'] for sample in train_samples]
train_candidate_items = set()
for cands in train_candidates:
    train_candidate_items.update(cands)

# Evaluation candidates
eval_candidates = load_rerank_candidates(...)
eval_candidate_items = set()
for user_cands in eval_candidates.values():
    eval_candidate_items.update(user_cands)

print(f"Training candidate items: {len(train_candidate_items)}")
print(f"Evaluation candidate items: {len(eval_candidate_items)}")
print(f"Overlap: {len(train_candidate_items & eval_candidate_items)}")

# Náº¿u overlap tháº¥p â†’ distribution khÃ¡c nhau
```

---

## ğŸ¯ Action Plan

### **Priority 1: Kiá»ƒm tra Model Save/Load** ğŸ”´

1. **ThÃªm logging**:
```python
# Sau training
print(f"[DEBUG] Model output dir: {training_args.output_dir}")
if os.path.exists(training_args.output_dir):
    checkpoints = [f for f in os.listdir(training_args.output_dir) if 'checkpoint' in f]
    print(f"[DEBUG] Checkpoints: {checkpoints}")
else:
    print(f"[DEBUG] Output dir does not exist!")
```

2. **Kiá»ƒm tra model cÃ³ Ä‘Æ°á»£c save khÃ´ng**:
```python
# Save model manually sau training
trainer.save_model("./qwen_rerank_final")
print(f"[DEBUG] Model saved to ./qwen_rerank_final")
```

3. **Kiá»ƒm tra model cÃ³ Ä‘Æ°á»£c load láº¡i khÃ´ng**:
```python
# Khi rerank, kiá»ƒm tra model state
print(f"[DEBUG] Model device: {self.model.device}")
print(f"[DEBUG] Model is training mode: {self.model.training}")
self.model.eval()  # âœ… Äáº£m báº£o eval mode
```

---

### **Priority 2: Kiá»ƒm tra Training Loss** ğŸ”´

1. **ThÃªm loss tracking**:
```python
# ThÃªm callback
from transformers import TrainerCallback

class LossCallback(TrainerCallback):
    def on_log(self, args, state, control, logs=None, **kwargs):
        if 'loss' in logs:
            print(f"[TRAINING] Step {state.global_step}: loss={logs['loss']:.4f}")

trainer.add_callback(LossCallback())
```

2. **Kiá»ƒm tra loss cÃ³ giáº£m khÃ´ng**:
- Initial loss: ~3.9 (random)
- Sau 1 epoch: ~2.5-3.5
- Sau 4 epochs: ~1.5-2.5

---

### **Priority 3: Test vá»›i nhiá»u Candidates** ğŸŸ¡

```python
# Test vá»›i 20-50 candidates
for num_cand in [5, 10, 20, 50]:
    prompt = build_prompt_with_n_candidates(num_cand)
    probs = model.predict_probs(prompt, num_candidates=num_cand)
    print(f"Candidates={num_cand}: std={np.std(probs):.4f}")
    
    # Náº¿u std giáº£m khi tÄƒng candidates â†’ model kÃ©m vá»›i nhiá»u candidates
```

---

### **Priority 4: Kiá»ƒm tra Training Data Quality** ğŸŸ¡

```python
# Kiá»ƒm tra distribution
targets = [sample['messages'][2]['content'] for sample in train_data_for_llm]
target_counts = Counter(targets)

# Náº¿u quÃ¡ imbalanced â†’ cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng
if max(target_counts.values()) / len(targets) > 0.5:
    print(f"[WARNING] Training data is imbalanced!")
    print(f"  Most common target: {max(target_counts, key=target_counts.get)} ({max(target_counts.values())/len(targets)*100:.1f}%)")
```

---

## ğŸ“Š Expected Results

### **Náº¿u Model Ä‘Æ°á»£c Train Ä‘Ãºng**:

- Training loss giáº£m tá»« ~3.9 â†’ ~1.5-2.5
- Model predict khÃ´ng uniform (std > 0.1)
- Recall@20 > 0.6 (khÃ´ng pháº£i 0.4)

### **Náº¿u Model khÃ´ng Ä‘Æ°á»£c Train Ä‘Ãºng**:

- Training loss khÃ´ng giáº£m hoáº·c giáº£m ráº¥t Ã­t
- Model predict gáº§n uniform
- Recall@20 â‰ˆ 0.4 (random)

---

## âœ… TÃ³m táº¯t

**Tests pass nhÆ°ng recall tháº¥p** â†’ Váº¥n Ä‘á» cÃ³ thá»ƒ lÃ :

1. ğŸ”´ **Model khÃ´ng Ä‘Æ°á»£c save/load Ä‘Ãºng** (CRITICAL)
2. ğŸ”´ **Training loss khÃ´ng giáº£m** (CRITICAL)
3. ğŸŸ¡ **Model kÃ©m vá»›i nhiá»u candidates** (20-50)
4. ğŸŸ¡ **Training data quality** (imbalanced)
5. ğŸŸ¡ **Model size quÃ¡ nhá»** (Qwen3-0.6B)

**Next Steps**:
1. âœ… Kiá»ƒm tra model save/load
2. âœ… Kiá»ƒm tra training loss
3. âœ… Test vá»›i nhiá»u candidates
4. âœ… Kiá»ƒm tra training data quality

