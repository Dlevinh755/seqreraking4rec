{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-29T03:28:46.981125Z",
     "iopub.status.busy": "2025-09-29T03:28:46.980413Z",
     "iopub.status.idle": "2025-09-29T03:30:14.900408Z",
     "shell.execute_reply": "2025-09-29T03:30:14.899592Z",
     "shell.execute_reply.started": "2025-09-29T03:28:46.981085Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 03:29:37.094011: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759116577.453030      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1759116577.553915      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "import os, re\n",
    "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
    "    !pip install unsloth\n",
    "else:\n",
    "    # Dùng khi chạy trên Colab\n",
    "    import torch; v = re.match(r\"[0-9\\.]{3,}\", str(torch.__version__)).group(0)\n",
    "    xformers = \"xformers==\" + (\"0.0.32.post2\" if v == \"2.8.0\" else \"0.0.29.post3\")\n",
    "    !pip install --no-deps bitsandbytes accelerate {xformers} peft trl triton cut_cross_entropy unsloth_zoo\n",
    "    !pip install sentencepiece protobuf \"datasets>=3.4.1,<4.0.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
    "    !pip install --no-deps unsloth\n",
    "!pip install transformers==4.55.4\n",
    "!pip install --no-deps trl==0.22.2\n",
    "\n",
    "import torch\n",
    "from unsloth import FastLanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T03:30:14.902138Z",
     "iopub.status.busy": "2025-09-29T03:30:14.901856Z",
     "iopub.status.idle": "2025-09-29T03:30:14.905991Z",
     "shell.execute_reply": "2025-09-29T03:30:14.905316Z",
     "shell.execute_reply.started": "2025-09-29T03:30:14.902109Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Kiểm tra số dòng trong train.jsonl\n",
    "# with open('/kaggle/input/processed-data1/train.jsonl', 'r', encoding='utf-8') as f:\n",
    "#     train_lines = sum(1 for line in f)\n",
    "\n",
    "# # Kiểm tra số dòng trong valid.jsonl\n",
    "# with open('/kaggle/input/processed-data1/val.jsonl', 'r', encoding='utf-8') as f:\n",
    "#     valid_lines = sum(1 for line in f)\n",
    "\n",
    "# print(f\"Số dòng trong train.jsonl: {train_lines}\")\n",
    "# print(f\"Số dòng trong valid.jsonl: {valid_lines}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T03:30:14.907003Z",
     "iopub.status.busy": "2025-09-29T03:30:14.906739Z",
     "iopub.status.idle": "2025-09-29T03:30:36.285052Z",
     "shell.execute_reply": "2025-09-29T03:30:36.284177Z",
     "shell.execute_reply.started": "2025-09-29T03:30:14.906972Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.9.9: Fast Qwen3 patching. Transformers: 4.55.4.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f0e637c6e04e51afc4cadedc758769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.51G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "833d34e2fc234b6389dffd0755317726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/238 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0ea0c97812405ab4e30b6579f11d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51f682e7efd2436283b9b8eaf8a050c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ef02558d7b7462498eabeb66f71216b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a1f408d82544a1299900a385b7a2c0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/707 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce9701e3f3df4388868f6df6be3edbb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af50fde17a71408f86f794a75c497b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3614426e7ad0424292b0280dc22cf866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tải model\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Qwen3-4B-Thinking-2507-unsloth-bnb-4bit\",\n",
    "    max_seq_length = 2048,\n",
    "    load_in_4bit = True,\n",
    "    load_in_8bit = False,\n",
    "    full_finetuning = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T03:30:36.287033Z",
     "iopub.status.busy": "2025-09-29T03:30:36.286621Z",
     "iopub.status.idle": "2025-09-29T03:30:44.312153Z",
     "shell.execute_reply": "2025-09-29T03:30:44.311353Z",
     "shell.execute_reply.started": "2025-09-29T03:30:36.287003Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cấu hình LoRA\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 32,\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_alpha = 32,\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,\n",
    "    loftq_config = None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T03:30:44.313200Z",
     "iopub.status.busy": "2025-09-29T03:30:44.312981Z",
     "iopub.status.idle": "2025-09-29T03:30:44.319296Z",
     "shell.execute_reply": "2025-09-29T03:30:44.318543Z",
     "shell.execute_reply.started": "2025-09-29T03:30:44.313182Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load chat template Qwen3\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"qwen3-thinking\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T03:30:44.320219Z",
     "iopub.status.busy": "2025-09-29T03:30:44.319935Z",
     "iopub.status.idle": "2025-09-29T03:30:50.586300Z",
     "shell.execute_reply": "2025-09-29T03:30:50.585611Z",
     "shell.execute_reply.started": "2025-09-29T03:30:44.320194Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "848113e710164f008acc96ab454cd670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6502b052582a4f93af284da3942eebf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==== Load dataset JSONL ====\n",
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset(\"json\", data_files=\"/kaggle/input/processed-data1/train.jsonl\", split=\"train\")\n",
    "val_dataset   = load_dataset(\"json\", data_files=\"/kaggle/input/processed-data1/val.jsonl\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T03:30:50.587455Z",
     "iopub.status.busy": "2025-09-29T03:30:50.587116Z",
     "iopub.status.idle": "2025-09-29T03:30:51.556941Z",
     "shell.execute_reply": "2025-09-29T03:30:51.556205Z",
     "shell.execute_reply.started": "2025-09-29T03:30:50.587431Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a491ec3486e4b369a9d8c4af8bb586b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6174 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868a93d34e9d49e9860b3ec452eca661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/687 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Map sang hội thoại\n",
    "def generate_conversation(examples):\n",
    "    instructions = examples[\"instruction\"]\n",
    "    inputs = examples[\"input\"]\n",
    "    outputs = examples[\"output\"]\n",
    "    conversations = []\n",
    "    for ins, inp, out in zip(instructions, inputs, outputs):\n",
    "        if inp and inp.strip():\n",
    "            user_prompt = ins.strip() + \"\\n\" + inp.strip()\n",
    "        else:\n",
    "            user_prompt = ins.strip()\n",
    "        conversations.append([\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "            {\"role\": \"assistant\", \"content\": out.strip()},\n",
    "        ])\n",
    "    return {\"conversations\": conversations}\n",
    "\n",
    "train_dataset = train_dataset.map(generate_conversation, batched=True)\n",
    "val_dataset   = val_dataset.map(generate_conversation, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T03:30:51.557844Z",
     "iopub.status.busy": "2025-09-29T03:30:51.557542Z",
     "iopub.status.idle": "2025-09-29T03:30:54.057582Z",
     "shell.execute_reply": "2025-09-29T03:30:54.056746Z",
     "shell.execute_reply.started": "2025-09-29T03:30:51.557820Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0415956dc03b4ad2bdd5bb374c21a4c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6174 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80c193670aec4bd7ad25c4a457547312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/687 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Format thành text input cho model\n",
    "def formatting_prompts_func(examples):\n",
    "    convos = examples[\"conversations\"]\n",
    "    texts = [tokenizer.apply_chat_template(\n",
    "        convo,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=False\n",
    "    ) for convo in convos]\n",
    "    return {\"text\": texts}\n",
    "\n",
    "train_dataset = train_dataset.map(formatting_prompts_func, batched=True)\n",
    "val_dataset   = val_dataset.map(formatting_prompts_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T03:34:06.697708Z",
     "iopub.status.busy": "2025-09-29T03:34:06.696910Z",
     "iopub.status.idle": "2025-09-29T08:18:07.657939Z",
     "shell.execute_reply": "2025-09-29T08:18:07.656970Z",
     "shell.execute_reply.started": "2025-09-29T03:34:06.697664Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 500 steps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92538292d2004c8d8b9029e1a7e1ba9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=8):   0%|          | 0/6174 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff5cb931ef541c7bf218a23e5f7cbca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=8):   0%|          | 0/687 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a76d50ef62db4ad085e242e60b2b74fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/6174 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1e621ef6eea40ff9b079861c5069347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/687 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 4:42:56, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.162500</td>\n",
       "      <td>2.189562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.099600</td>\n",
       "      <td>2.132513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.064800</td>\n",
       "      <td>2.107159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.033900</td>\n",
       "      <td>2.096127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.058300</td>\n",
       "      <td>2.094072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==== Training 500 steps cho GPU T4 15GB (đã sửa lỗi) ====\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from unsloth.chat_templates import train_on_responses_only\n",
    "\n",
    "# Config với 500 steps\n",
    "max_steps = 500\n",
    "\n",
    "print(f\"Training for {max_steps} steps\")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = val_dataset,\n",
    "    args = SFTConfig(\n",
    "        dataset_text_field = \"text\",\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 50,\n",
    "        max_steps = max_steps,\n",
    "        learning_rate = 5e-5,\n",
    "        logging_steps = 25,\n",
    "        eval_steps = 100,\n",
    "        save_steps = 100,  # Sửa thành bội số của eval_steps\n",
    "        eval_strategy = \"steps\",\n",
    "        save_strategy = \"steps\",\n",
    "        load_best_model_at_end = True,\n",
    "        metric_for_best_model = \"eval_loss\",\n",
    "        greater_is_better = False,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"cosine\",\n",
    "        seed = 3407,\n",
    "        report_to = \"none\",\n",
    "        max_grad_norm = 0.5,\n",
    "        fp16 = True,\n",
    "        bf16 = False,\n",
    "        dataloader_pin_memory = False,\n",
    "        gradient_checkpointing = True,\n",
    "        gradient_checkpointing_kwargs = {\"use_reentrant\": False},\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Chỉ train trên response\n",
    "trainer = train_on_responses_only(\n",
    "    trainer,\n",
    "    instruction_part = \"<|im_start|>user\\n\",\n",
    "    response_part = \"<|im_start|>assistant\\n\",\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T08:18:53.567665Z",
     "iopub.status.busy": "2025-09-29T08:18:53.566848Z",
     "iopub.status.idle": "2025-09-29T08:18:54.399298Z",
     "shell.execute_reply": "2025-09-29T08:18:54.398611Z",
     "shell.execute_reply.started": "2025-09-29T08:18:53.567635Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('lora_model/tokenizer_config.json',\n",
       " 'lora_model/special_tokens_map.json',\n",
       " 'lora_model/chat_template.jinja',\n",
       " 'lora_model/vocab.json',\n",
       " 'lora_model/merges.txt',\n",
       " 'lora_model/added_tokens.json',\n",
       " 'lora_model/tokenizer.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lưu model\n",
    "model.save_pretrained(\"lora_model\")\n",
    "tokenizer.save_pretrained(\"lora_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T08:29:40.339418Z",
     "iopub.status.busy": "2025-09-29T08:29:40.338467Z",
     "iopub.status.idle": "2025-09-29T08:31:02.953417Z",
     "shell.execute_reply": "2025-09-29T08:31:02.952637Z",
     "shell.execute_reply.started": "2025-09-29T08:29:40.339391Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.9.9: Fast Qwen3 patching. Transformers: 4.55.4.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Final output:\n",
      " <think>\n",
      "</think>\n",
      "\n",
      "Đáp án: Một rối loạn ăn kiêng (EDM) là một nhóm các tình trạng liên quan đến việc tiêu thụ thức ăn và sự thèm ăn bất thường trong đó có nhiều yếu tố tâm lý, xã hội, lạm dụng hóa chất hoặc bệnh tật.Phân loại EDM được phân loại thành 6 nhóm chính: chứng khó chịu về cân nặng, nghiện thực phẩm, rối loạn chế độ ăn kiếng, rối hợp đồng và hành vi tự gây ra.Tình trạng này đã xảy ra ở cả nam giới và nữ giới.Mặc dù nó có thể ảnh hưởng đến mọi người khác nhau từ trẻ em đến già, nhưng nó phổ biến nhất ở tuổi trưởng thành.Nó cũng có thể phát triển sau khi trải qua căng thẳng lớn.Các triệu chứng của EDN phụ thuộc vào nguyên nhân cụ thể.Trong số những người mắc chứng khó đọc, chúng bao gồm cảm giác đau đớn với trọng lượng cơ thể quá cao hoặc thấp;với chứng khó khăn về cân năng, họ bị lo lắng về hình dạng và kích thước của mình;và với chứng khó nhận thức, họ có xu hướng nạp lại hoặc giảm caloric hơn mức cần thiết để duy trì cân bằng dinh dưỡng.Bệnh EDN cũng có liên hệ chặt chẽ với trầm cảm, mất ngủ, rối thần kinh chuyển động, rối nhiễu giấc mơ, rối nhiệt, rối lạc và rối loạn chức năng sinh dục.Việc sử dụng thuốc chống trầm cảm như SSRIs làm tăng nguy cơ mắc phải chứng khó ăn kiếc vì chúng có tác dụng phụ khiến người dùng buồn nôn.Dấu hiệu và triệu chứng Các dấu hiệu và biểu hiện của EDI rất đa dạng tùy thuộc vào liệu bệnh nhân đang gặp vấn đề với chứng sợ hãi về cân bằng, chứng khó chấp nhận hay chứng khó hiểu.Khi nói đến chứng sợ cân nặng thì các đặc điểm điển hình là suy nghĩ tiêu cực về ngoại hình, sự lo lắng quá mức về trọng lượng và kích cỡ cơ thể, mặc dù có khả năng giảm cân đáng kể sẽ xảy ra.Họ cũng có xu thế chọn đồ ăn ít calo hơn so với nhu cầu của họ và cố gắng tránh ăn đủ.Thiếu hụt canxi và vitamin D dẫn đến xương nhỏ và sút cân do thiếu canxi, cũng như rụng tóc nghiêm trọng.Chứng khó chấp thuận về cân đối với chứng phàn nàn về cân lực là những người có thể đạt được cân nặng mong muốn của họ mà không có ý định giảm cân hoặc tăng cân thêm.Xem xét cân nặng của họ, họ thấy rằng họ quá mảnh dẻ hoặc thừa cân.Liệu pháp cho chứng khó thở về cân cân chỉ tập trung vào việc giúp họ quản lý cảm xúc và điều chỉnh tư duy sai lệch của họ.Chúng tôi cũng khuyến khích họ đi bộ và tập gym để giữ dáng và xây dựng khối cơ.Chứng phàn.nàn về cái nhìn về cân nhắc cho chứng phì đại là những cá nhân có xu Hướng ăn quá nhiều thực phẩm giàu calo, chẳng hạn như bánh ngọt, nước ép trái cây đường, kem, v.v., hoặc thậm chí là rượu bia.Sự gia tăng cân nhanh chóng dẫn đến việc bỏ phiếu tích cực về cân lượng, dẫn đến sự thất vọng và lo lắng hơn nữa.Loại bỏ các thực phẩm này khỏi danh sách thực đơn có thể giúp cải thiện kết quả.Một nghiên cứu năm 2015 trên 479 bệnh nhân mắc chứng phìn về cân đã tìm thấy mối tương quan giữa lượng carbohydrate tiêu thụ hàng ngày và tỷ lệ mắc chứng phù đại. Chẩn đoán chẩn đoán chứng khó dung nạp đòi hỏi đánh giá toàn diện của lịch sử sức khỏe của bệnh nhân cùng với các triệu chứng và kiểm tra thể chất.Quản trị chấm dứt chế độ nhịn ăn và phục hồi cân nặng bình thường. Những người mắc bệnh nên được khuyên nên ăn đầy đủ và đều đặn mỗi bữa ăn, tránh ăn quá sớm hoặc quá muộn trước khi hoạt động thể chất.Phòng ngừa không có cách nào để ngăn chặn chứng khó tính nếu bạn có tiền sử di truyền của nó, nhưng bạn có thể phòng ngừa nó thông qua chế độ vận động lành mạnh, chế độ dinh dư lượng tốt và một cuộc sống thoải mái.Tài liệu tham khảo == Liên kết bên ngoài ==\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import TextStreamer\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "# Load model và tokenizer đã fine-tuned\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"/kaggle/working/lora_model\",\n",
    "    max_seq_length = 2048,\n",
    "    load_in_4bit = True,\n",
    ")\n",
    "\n",
    "device = next(model.parameters()).device\n",
    "\n",
    "def ask(question: str, max_new_tokens: int = 1000):\n",
    "    # Hội thoại input với chỉ dẫn rõ ràng\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": question + \" Trả lời ngắn gọn, chính xác theo y học hiện đại, không bịa đặt.\"}\n",
    "    ]\n",
    "\n",
    "    # Tạo prompt, tắt reasoning (<think>)\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "        enable_thinking=False,   # <- tắt <think>\n",
    "    )\n",
    "\n",
    "    # Tokenize và đưa lên device\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Generate với cấu hình an toàn hơn\n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        temperature=0.5,\n",
    "        top_p=0.9,\n",
    "        top_k=50,\n",
    "        repetition_penalty=1.2,\n",
    "        no_repeat_ngram_size=3,\n",
    "        early_stopping=True,\n",
    "    )\n",
    "\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    # Chỉ lấy phần sau \"assistant\"\n",
    "    if \"assistant\" in decoded:\n",
    "        decoded = decoded.split(\"assistant\", 1)[-1].strip()\n",
    "\n",
    "    return decoded\n",
    "\n",
    "# Ví dụ test\n",
    "print(\"Final output:\\n\", ask(\"Hỏi: Rối loạn ăn uống là gì?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T08:40:18.504263Z",
     "iopub.status.busy": "2025-09-29T08:40:18.503940Z",
     "iopub.status.idle": "2025-09-29T08:40:33.069475Z",
     "shell.execute_reply": "2025-09-29T08:40:33.068580Z",
     "shell.execute_reply.started": "2025-09-29T08:40:18.504241Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã tạo file zip: /kaggle/working/lora_model.zip\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Đường dẫn thư mục bạn muốn nén\n",
    "folder_path = \"/kaggle/working/lora_model\"\n",
    "\n",
    "# Tên file zip sẽ tạo ra\n",
    "zip_file_path = \"/kaggle/working/lora_model.zip\"\n",
    "\n",
    "# Nén thư mục thành file zip\n",
    "shutil.make_archive(zip_file_path.replace(\".zip\", \"\"), 'zip', folder_path)\n",
    "\n",
    "print(\"Đã tạo file zip:\", zip_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8357064,
     "sourceId": 13187497,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
