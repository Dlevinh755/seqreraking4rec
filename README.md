# Sequential Reranking for Recommendation

Há»‡ thá»‘ng recommendation hai giai Ä‘oáº¡n (Two-Stage): **Retrieval (Stage 1)** + **Reranking (Stage 2)** vá»›i há»— trá»£ multimodal (images, text, captions).

## ğŸ“‹ Tá»•ng quan

Pipeline recommendation hai giai Ä‘oáº¡n:
- **Stage 1 (Retrieval)**: Generate candidates tá»« toÃ n bá»™ item pool
- **Stage 2 (Reranking)**: Re-rank candidates tá»« Stage 1 Ä‘á»ƒ táº¡o final recommendations

### âœ¨ TÃ­nh nÄƒng chÃ­nh

- âœ… **4 Retrieval methods**: LRURec, MMGCN, VBPR, BM3
- âœ… **5 Rerank methods**: Qwen (LLM), Qwen3-VL (MLLM, 4 modes), VIP5, BERT4Rec
- âœ… **Multimodal support**: Images, text, captions (BLIP2), semantic summaries (Qwen3-VL)
- âœ… **Training Ä‘á»™c láº­p**: CÃ³ thá»ƒ train tá»«ng stage riÃªng hoáº·c end-to-end
- âœ… **Evaluation metrics**: Recall@K, NDCG@K, Hit@K táº¡i @5, @10, @20
- âœ… **Early stopping**: Per-epoch validation vá»›i early stopping

## ğŸ“¦ CÃ i Ä‘áº·t

```bash
# CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt

# CÃ i Ä‘áº·t transformers tá»« source (cáº§n cho Qwen3-VL)
pip install git+https://github.com/huggingface/transformers
```

## ğŸš€ Quick Start

### BÆ°á»›c 1: Prepare Data

```bash
# Basic (chá»‰ ratings)
python data_prepare.py \
    --dataset_code beauty \
    --min_rating 3 \
    --min_uc 20 \
    --min_sc 20

# Vá»›i images vÃ  text (cho MMGCN, VBPR, BM3)
python data_prepare.py \
    --dataset_code beauty \
    --min_rating 3 \
    --min_uc 20 \
    --min_sc 20 \
    --use_image \
    --use_text

# Vá»›i captions (cho Qwen3-VL caption mode)
python data_prepare.py \
    --dataset_code beauty \
    --min_rating 3 \
    --min_uc 20 \
    --min_sc 20 \
    --use_image \
    --generate_caption

# Vá»›i semantic summaries (cho Qwen3-VL semantic_summary mode)
python data_prepare.py \
    --dataset_code beauty \
    --min_rating 3 \
    --min_uc 20 \
    --min_sc 20 \
    --use_image \
    --generate_semantic_summary
```

### BÆ°á»›c 2: Train Retrieval (Stage 1)

```bash
# LRURec (khÃ´ng cáº§n images/text)
python scripts/train_retrieval.py --retrieval_method lrurec

# MMGCN (cáº§n images/text)
python scripts/train_retrieval.py --retrieval_method mmgcn

# VBPR (cáº§n images)
python scripts/train_retrieval.py --retrieval_method vbpr

# BM3 (cáº§n images + text)
python scripts/train_retrieval.py --retrieval_method bm3
```

### BÆ°á»›c 3: Train Rerank (Stage 2)

#### Standalone (khÃ´ng cáº§n retrieval model)

```bash
# Qwen LLM (text-only)
python scripts/train_rerank_standalone.py \
    --rerank_method qwen \
    --mode ground_truth

# Qwen3-VL (multimodal, 4 modes)
python scripts/train_rerank_standalone.py \
    --rerank_method qwen3vl \
    --mode ground_truth \
    --qwen_mode raw_image  # hoáº·c: caption, semantic_summary, semantic_summary_small

# VIP5 (multimodal T5)
python scripts/train_rerank_standalone.py \
    --rerank_method vip5 \
    --mode ground_truth

# BERT4Rec (sequential)
python scripts/train_rerank_standalone.py \
    --rerank_method bert4rec \
    --mode ground_truth
```

#### Vá»›i Retrieval Model (Full Pipeline)

```bash
python scripts/train_rerank_standalone.py \
    --rerank_method qwen \
    --mode retrieval \
    --retrieval_method lrurec \
    --retrieval_top_k 200 \
    --rerank_top_k 50
```

### BÆ°á»›c 4: Train End-to-End (Stage 1 + Stage 2)

```bash
python scripts/train_pipeline.py \
    --retrieval_method lrurec \
    --retrieval_top_k 200 \
    --rerank_method qwen \
    --rerank_top_k 50 \
    --rerank_mode retrieval
```

## ğŸ“Š Methods Available

### Retrieval Methods (Stage 1)

| Method | Description | Requirements | Command |
|--------|-------------|-------------|---------|
| `lrurec` | Neural LRU-based sequential | Dataset cÆ¡ báº£n | `--retrieval_method lrurec` |
| `mmgcn` | Multimodal Graph Convolutional Network | Images/text + CLIP | `--retrieval_method mmgcn` |
| `vbpr` | Visual Bayesian Personalized Ranking | Images + CLIP | `--retrieval_method vbpr` |
| `bm3` | Bootstrap Latent Representations | Images + text + CLIP | `--retrieval_method bm3` |

### Rerank Methods (Stage 2)

| Method | Description | Requirements | Command |
|--------|-------------|-------------|---------|
| `qwen` | Qwen LLM (text-only) | Text data | `--rerank_method qwen` |
| `qwen3vl` | Qwen3-VL (multimodal, unified) | TÃ¹y mode | `--rerank_method qwen3vl --qwen_mode <mode>` |
| `vip5` | VIP5 multimodal T5 | Images + CLIP | `--rerank_method vip5` |
| `bert4rec` | BERT4Rec sequential | Sequential data | `--rerank_method bert4rec` |

### Qwen/Qwen3-VL Modes

| Mode | Description | Model | Data Preparation |
|------|-------------|-------|------------------|
| `text_only` | Chá»‰ dÃ¹ng text/description | `qwen3-0.6b`, `qwen3-1.6b` | Text data |
| `raw_image` | Raw images trong prompt | `qwen3-2bvl` | `--use_image` |
| `caption` | Image captions (BLIP2) | `qwen3-0.6b`, `qwen3-1.6b`, `qwen3-2bvl` | `--use_image --generate_caption` |
| `semantic_summary` | Semantic summaries (Qwen3-VL) | `qwen3-0.6b`, `qwen3-1.6b`, `qwen3-2bvl` | `--use_image --generate_semantic_summary` |

### Rerank Modes

| Mode | Description | Use Case |
|------|-------------|----------|
| `retrieval` | DÃ¹ng candidates tá»« Stage 1 | Full pipeline evaluation |
| `ground_truth` | GT + 19 random negatives | Rerank quality evaluation (independent) |

## âš™ï¸ Configuration

CÃ¡c hyperparameters cÃ³ thá»ƒ Ä‘iá»u chá»‰nh trong `config.py` hoáº·c command-line:

### Retrieval
- `--retrieval_epochs`: Sá»‘ epochs (default: 100)
- `--retrieval_lr`: Learning rate (default: 1e-4)
- `--batch_size_retrieval`: Batch size (default: 512)
- `--retrieval_patience`: Early stopping patience (default: 10)

### Rerank
- `--rerank_epochs`: Sá»‘ epochs (default: 10)
- `--rerank_lr`: Learning rate (default: 1e-4)
- `--rerank_batch_size`: Batch size cho LLM training (default: 16)
- `--rerank_patience`: Early stopping patience (default: 5)
- `--rerank_eval_candidates`: Sá»‘ candidates cho evaluation vÃ  data preparation (default: 50)
  - DÃ¹ng cho ground_truth mode: táº¡o 1 GT + (N-1) negatives
  - DÃ¹ng cho pre-generating candidates trong `data_prepare.py`

### Qwen LLM Reranker
- `--qwen_mode`: Prompt mode (`text_only`, `caption`, `semantic_summary`) - thay tháº¿ `--qwen3vl_mode`
- `--qwen_model`: Model name (`qwen3-0.6b`, `qwen3-1.6b`, `qwen3-2bvl`)
- `--qwen_max_candidates`: Sá»‘ candidates tá»‘i Ä‘a trong prompt (default: 50)
  - Náº¿u None, dÃ¹ng táº¥t cáº£ candidates tá»« retrieval
  - NÃªn set = `rerank_eval_candidates` Ä‘á»ƒ nháº¥t quÃ¡n
- `--qwen_max_history`: Sá»‘ items trong user history (default: 5)
  - History sáº½ bá»‹ truncate vá» N items cuá»‘i cÃ¹ng náº¿u dÃ i hÆ¡n
- `--qwen_max_seq_length`: Max sequence length cho LLM (default: 2048)
  - TÄƒng lÃªn 4096 hoáº·c 8192 náº¿u cÃ³ nhiá»u candidates (50+)
  - Raw image mode tá»± Ä‘á»™ng dÃ¹ng 2x giÃ¡ trá»‹ nÃ y (4096 náº¿u default)

### Qwen3-VL (Legacy - dÃ¹ng `--qwen_mode` thay tháº¿)
- `--qwen3vl_mode`: [DEPRECATED] DÃ¹ng `--qwen_mode` thay tháº¿
- `--semantic_summary_batch_size`: Batch size cho summary generation (default: 4)

### Performance
- `--use_quantization`: 4-bit quantization (tiáº¿t kiá»‡m memory)
- `--use_torch_compile`: torch.compile() optimization (tÄƒng tá»‘c)

## ğŸ“ Output Structure

```
data/preprocessed/{dataset_code}_min_rating{min_rating}-min_uc{min_uc}-min_sc{min_sc}/
â”œâ”€â”€ dataset_single_export.csv      # Dataset vá»›i metadata
â”œâ”€â”€ clip_embeddings.pt              # CLIP embeddings (náº¿u cÃ³)
â”œâ”€â”€ blip2_captions.pt               # BLIP2 captions cache (náº¿u cÃ³)
â””â”€â”€ qwen3vl_semantic_summaries.pt   # Semantic summaries cache (náº¿u cÃ³)

experiments/
â”œâ”€â”€ retrieval/{method}/{dataset_code}/seed{seed}/
â”‚   â”œâ”€â”€ retrieved.csv               # Retrieved candidates
â”‚   â””â”€â”€ retrieved_metrics.json     # Evaluation metrics
â””â”€â”€ rerank/{method}/{dataset_code}/seed{seed}/
    â”œâ”€â”€ model.pt                    # Trained model
    â””â”€â”€ metrics.json                 # Evaluation metrics
```

## ğŸ“ˆ Evaluation Metrics

Táº¥t cáº£ evaluation tá»± Ä‘á»™ng tÃ­nh **Recall@K**, **NDCG@K**, **Hit@K** táº¡i **@5, @10, @20**:

```
Metric       @5        @10        @20
Recall     0.1234    0.2345    0.3456
Ndcg       0.0567    0.0890    0.1234
Hit        0.4500    0.6700    0.8900
```

## ğŸ’¡ Important Notes

1. **Data Preparation Order**:
   - Cháº¡y `data_prepare.py` vá»›i Ä‘Ãºng flags trÆ°á»›c khi train
   - MMGCN/VBPR/BM3 cáº§n `--use_image` hoáº·c `--use_text`
   - Qwen caption mode cáº§n `--generate_caption`
   - Qwen semantic_summary mode cáº§n `--generate_semantic_summary`
   - `--rerank_eval_candidates` xÃ¡c Ä‘á»‹nh sá»‘ candidates Ä‘Æ°á»£c pre-generate cho evaluation

2. **Training Modes**:
   - **Standalone**: Train tá»«ng stage riÃªng (`train_retrieval.py`, `train_rerank_standalone.py`)
   - **End-to-end**: Train cáº£ 2 stages (`train_pipeline.py`)

3. **Ground Truth Mode**:
   - DÃ¹ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ rerank quality Ä‘á»™c láº­p vá»›i retrieval
   - Táº¡o candidates = [ground_truth] + (N-1) random negatives (N = `rerank_eval_candidates`)
   - KhÃ´ng cáº§n retrieval model
   - Sá»‘ candidates cÃ³ thá»ƒ Ä‘iá»u chá»‰nh qua `--rerank_eval_candidates`

4. **Qwen LLM Configuration**:
   - `--qwen_max_candidates`: Giá»›i háº¡n sá»‘ candidates trong prompt (default: 50)
     - Náº¿u set nhá» hÆ¡n sá»‘ candidates thá»±c táº¿, sáº½ truncate vá» N Ä‘áº§u tiÃªn
     - NÃªn set = `rerank_eval_candidates` Ä‘á»ƒ nháº¥t quÃ¡n
   - `--qwen_max_history`: Sá»‘ items trong history (default: 5)
     - History dÃ i hÆ¡n sáº½ bá»‹ truncate vá» N items cuá»‘i cÃ¹ng
   - `--qwen_max_seq_length`: Max sequence length (default: 2048)
     - TÄƒng lÃªn 4096 hoáº·c 8192 náº¿u cÃ³ nhiá»u candidates (50+)
     - Raw image mode tá»± Ä‘á»™ng dÃ¹ng 2x giÃ¡ trá»‹ nÃ y
   - Táº¥t cáº£ configs tá»± Ä‘á»™ng láº¥y tá»« `config.py` náº¿u khÃ´ng set khi khá»Ÿi táº¡o

5. **CLIP Embeddings**:
   - Tá»± Ä‘á»™ng extract khi cháº¡y `data_prepare.py` vá»›i `--use_image` hoáº·c `--use_text`
   - Cáº§n cho MMGCN, VBPR, BM3, VIP5

6. **Image Processing**:
   - Tá»± Ä‘á»™ng resize vá» 224Ã—224 (giá»¯ aspect ratio)
   - Tiáº¿t kiá»‡m memory vÃ  tÄƒng tá»‘c xá»­ lÃ½

7. **LLM Tokenization**:
   - Code tá»± Ä‘á»™ng tÃ¬m number tokens vá»›i nhiá»u strategies (direct, space-prefixed, encoded)
   - Probabilities Ä‘Æ°á»£c normalize Ä‘á»ƒ sum to 1
   - Fallback vá» uniform distribution náº¿u khÃ´ng tÃ¬m tháº¥y number tokens

## ğŸ”§ Troubleshooting

- **Qwen3-VL khÃ´ng load**: CÃ i transformers tá»« source: `pip install git+https://github.com/huggingface/transformers`
- **Out of memory**: 
  - Giáº£m batch size trong `config.py` (`--rerank_batch_size`)
  - Giáº£m `--qwen_max_candidates` hoáº·c `--rerank_eval_candidates`
  - DÃ¹ng `--use_quantization` (Ä‘Ã£ enable máº·c Ä‘á»‹nh cho Unsloth models)
- **CLIP embeddings khÃ´ng tÃ¬m tháº¥y**: Cháº¡y `data_prepare.py` vá»›i `--use_image` hoáº·c `--use_text`
- **Prompts bá»‹ truncate**: TÄƒng `--qwen_max_seq_length` lÃªn 4096 hoáº·c 8192
- **Chá»‰ cÃ³ 20 candidates trong prompt**: 
  - Kiá»ƒm tra `--qwen_max_candidates` vÃ  `--rerank_eval_candidates` trong config
  - Äáº£m báº£o `qwen_max_candidates >= rerank_eval_candidates`
- **LLM reranker thua random**: 
  - Kiá»ƒm tra debug output vá» number tokens
  - Äáº£m báº£o model Ä‘Æ°á»£c train Ä‘á»§ epochs
  - Kiá»ƒm tra training data format (target pháº£i lÃ  sá»‘, khÃ´ng pháº£i text)

## ğŸ“š Cáº¥u trÃºc Project

```
seqreraking4rec/
â”œâ”€â”€ config.py                    # Main configuration
â”œâ”€â”€ data_prepare.py              # Data preprocessing
â”œâ”€â”€ dataset/                     # Dataset modules
â”‚   â”œâ”€â”€ base.py                  # Base dataset class
â”‚   â”œâ”€â”€ beauty.py                # Amazon Beauty
â”‚   â”œâ”€â”€ games.py                 # Video Games
â”‚   â””â”€â”€ ml_100k.py               # MovieLens
â”œâ”€â”€ retrieval/                   # Stage 1: Retrieval
â”‚   â”œâ”€â”€ base.py                  # BaseRetriever interface
â”‚   â”œâ”€â”€ methods/                  # Retrieval methods
â”‚   â””â”€â”€ models/                  # PyTorch models
â”œâ”€â”€ rerank/                      # Stage 2: Reranking
â”‚   â”œâ”€â”€ base.py                  # BaseReranker interface
â”‚   â”œâ”€â”€ methods/                  # Rerank methods
â”‚   â””â”€â”€ models/                  # PyTorch models
â””â”€â”€ scripts/                     # Training scripts
    â”œâ”€â”€ train_retrieval.py        # Train retrieval only
    â”œâ”€â”€ train_rerank_standalone.py # Train rerank only
    â””â”€â”€ train_pipeline.py         # Train end-to-end
```

## ğŸ”„ Recent Updates

### Version 2.0 (Latest)

- âœ… **Unified Qwen Reranker**: Gá»™p `qwen_reranker.py` vÃ  `qwen3vl_reranker.py` thÃ nh `qwen_reranker_unified.py`
- âœ… **Config-driven**: Táº¥t cáº£ LLM parameters cÃ³ thá»ƒ config tá»« `config.py`:
  - `qwen_max_candidates`: Sá»‘ candidates tá»‘i Ä‘a (default: 50)
  - `qwen_max_history`: Sá»‘ items trong history (default: 5)
  - `qwen_max_seq_length`: Max sequence length (default: 2048)
  - `rerank_eval_candidates`: Sá»‘ candidates cho evaluation (default: 50)
- âœ… **Improved Tokenization**: Multiple strategies Ä‘á»ƒ tÃ¬m number tokens (direct, space-prefixed, encoded)
- âœ… **Probability Normalization**: Tá»± Ä‘á»™ng normalize probabilities vÃ  fallback vá» uniform náº¿u cáº§n
- âœ… **Debug Output**: Warnings khi khÃ´ng tÃ¬m tháº¥y Ä‘á»§ number tokens hoáº·c probabilities = 0
- âœ… **Checkpoint Evaluation**: Notebook `eval_from_checkpoint.ipynb` Ä‘á»ƒ load vÃ  eval model tá»« checkpoint

### Breaking Changes

- `--qwen3vl_mode` â†’ `--qwen_mode` (backward compatible, nhÆ°ng nÃªn dÃ¹ng má»›i)
- Default `rerank_eval_candidates` vÃ  `qwen_max_candidates` thay Ä‘á»•i tá»« 20 â†’ 50

## ğŸ“ License

[Add your license here]
