# Sequential Reranking for Recommendation

Há»‡ thá»‘ng recommendation hai giai Ä‘oáº¡n (Two-Stage): Retrieval (Stage 1) + Reranking (Stage 2).

## ğŸ“‹ Tá»•ng quan

Project nÃ y implement má»™t pipeline recommendation hai giai Ä‘oáº¡n:
- **Stage 1 (Retrieval)**: Generate candidates tá»« toÃ n bá»™ item pool
- **Stage 2 (Reranking)**: Re-rank candidates tá»« Stage 1 Ä‘á»ƒ táº¡o final recommendations

### Features
- âœ… 4 Retrieval methods: LRURec, MMGCN, VBPR, BM3
- âœ… 5 Rerank methods: Qwen, Qwen3-VL (4 modes), VIP5, BERT4Rec
- âœ… Multimodal support: Images, text, captions, semantic summaries
- âœ… Training vÃ  evaluation Ä‘á»™c láº­p cho tá»«ng stage
- âœ… Evaluation metrics: Recall@K, NDCG@K, Hit@K táº¡i @5, @10, @20
- âœ… Image preprocessing: Tá»± Ä‘á»™ng resize vá» 448px
- âœ… Per-epoch validation vá»›i early stopping

## ğŸ“¦ CÃ i Ä‘áº·t

### 1. CÃ i Ä‘áº·t dependencies

```bash
# CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cÆ¡ báº£n
pip install -r requirements.txt

# CÃ i Ä‘áº·t transformers tá»« source (cáº§n cho Qwen3-VL)
pip install git+https://github.com/huggingface/transformers
```

### 2. Cáº¥u hÃ¬nh dataset

Chá»‰nh sá»­a `config.py` hoáº·c sá»­ dá»¥ng command-line arguments Ä‘á»ƒ cáº¥u hÃ¬nh dataset vÃ  hyperparameters.

## ğŸš€ Cháº¡y Project

### BÆ°á»›c 1: Prepare Data

```bash
# Basic data preparation
python data_prepare.py \
    --dataset_code beauty \
    --min_rating 3 \
    --min_uc 20 \
    --min_sc 20

# Vá»›i image filtering vÃ  CLIP embeddings
python data_prepare.py \
    --dataset_code beauty \
    --min_rating 3 \
    --min_uc 20 \
    --min_sc 20 \
    --use_image \
    --use_text

# Vá»›i caption generation (BLIP2)
python data_prepare.py \
    --dataset_code beauty \
    --min_rating 3 \
    --min_uc 20 \
    --min_sc 20 \
    --use_image \
    --generate_caption

# Vá»›i semantic summary generation (Qwen3-VL)
python data_prepare.py \
    --dataset_code beauty \
    --min_rating 3 \
    --min_uc 20 \
    --min_sc 20 \
    --use_image \
    --generate_semantic_summary
```

### BÆ°á»›c 2: Train Retrieval (Stage 1)

```bash
# Neural LRURec
python scripts/train_retrieval.py --retrieval_method lrurec

# MMGCN (requires CLIP embeddings)
python scripts/train_retrieval.py --retrieval_method mmgcn

# VBPR (requires CLIP image embeddings)
python scripts/train_retrieval.py --retrieval_method vbpr

# BM3 (requires CLIP embeddings)
python scripts/train_retrieval.py --retrieval_method bm3
```

### BÆ°á»›c 3: Train Rerank (Stage 2) - Standalone

```bash
# Train rerank riÃªng láº» - Ground truth mode (khÃ´ng cáº§n retrieval)
python scripts/train_rerank_standalone.py \
    --rerank_method bert4rec \
    --mode ground_truth \
    --rerank_top_k 50

# Train rerank vá»›i retrieval Ä‘Ã£ train sáºµn
python scripts/train_rerank_standalone.py \
    --rerank_method qwen \
    --mode retrieval \
    --retrieval_method lrurec \
    --retrieval_top_k 200 \
    --rerank_top_k 50

# Train Qwen3-VL reranker (raw_image mode)
# Note: qwen3vl_mode Ä‘Æ°á»£c láº¥y tá»« config.py (--qwen3vl_mode raw_image)
python scripts/train_rerank_standalone.py \
    --rerank_method qwen3vl \
    --mode ground_truth \
    --rerank_top_k 50
# Set qwen3vl_mode trong config.py trÆ°á»›c khi cháº¡y: --qwen3vl_mode raw_image
```

### BÆ°á»›c 4: Train Pipeline (Stage 1 + Stage 2) - End-to-End

```bash
# Full pipeline vá»›i Qwen reranker
python scripts/train_pipeline.py \
    --retrieval_method lrurec \
    --retrieval_top_k 20 \
    --rerank_method qwen \
    --rerank_top_k 10 \
    --rerank_mode retrieval

# Full pipeline vá»›i Qwen3-VL reranker (raw_image mode)
# Note: qwen3vl_mode Ä‘Æ°á»£c láº¥y tá»« config.py (--qwen3vl_mode raw_image)
python scripts/train_pipeline.py \
    --retrieval_method lrurec \
    --retrieval_top_k 200 \
    --rerank_method qwen3vl \
    --rerank_top_k 50 \
    --rerank_mode retrieval

# Full pipeline vá»›i Qwen3-VL reranker (caption mode)
# Note: Set qwen3vl_mode trong config.py hoáº·c dÃ¹ng --qwen3vl_mode trong command line
python scripts/train_pipeline.py \
    --retrieval_method lrurec \
    --retrieval_top_k 200 \
    --rerank_method qwen3vl \
    --rerank_top_k 50 \
    --rerank_mode retrieval
# Set qwen3vl_mode trong config.py: --qwen3vl_mode caption

# Full pipeline vá»›i Qwen3-VL reranker (semantic_summary mode)
python scripts/train_pipeline.py \
    --retrieval_method lrurec \
    --retrieval_top_k 200 \
    --rerank_method qwen3vl \
    --rerank_top_k 50 \
    --rerank_mode retrieval
# Set qwen3vl_mode trong config.py: --qwen3vl_mode semantic_summary

# Full pipeline vá»›i Qwen3-VL reranker (semantic_summary_small mode)
python scripts/train_pipeline.py \
    --retrieval_method lrurec \
    --retrieval_top_k 200 \
    --rerank_method qwen3vl \
    --rerank_top_k 50 \
    --rerank_mode retrieval
# Set qwen3vl_mode trong config.py: --qwen3vl_mode semantic_summary_small

# Full pipeline vá»›i VIP5 reranker
python scripts/train_pipeline.py \
    --retrieval_method lrurec \
    --retrieval_top_k 200 \
    --rerank_method vip5 \
    --rerank_top_k 50 \
    --rerank_mode retrieval

# Full pipeline vá»›i BERT4Rec reranker
python scripts/train_pipeline.py \
    --retrieval_method lrurec \
    --retrieval_top_k 200 \
    --rerank_method bert4rec \
    --rerank_top_k 50 \
    --rerank_mode retrieval

# Ground truth mode (Ä‘Ã¡nh giÃ¡ rerank quality)
python scripts/train_pipeline.py \
    --retrieval_method lrurec \
    --retrieval_top_k 200 \
    --rerank_method qwen \
    --rerank_top_k 10 \
    --rerank_mode ground_truth
```

### BÆ°á»›c 5: Offline Evaluation

Táº¥t cáº£ evaluation tá»± Ä‘á»™ng tÃ­nh metrics cho @5, @10, @20 vá»›i Recall, NDCG, vÃ  Hit Rate trÃªn cáº£ **val** vÃ  **test** sets.

```bash
# Evaluate retrieval only
python evaluation/offline_eval.py \
    --mode retrieval \
    --retrieval_method lrurec \
    --retrieval_top_k 200 \
    --split val  # or --split test

# Evaluate full pipeline vá»›i Qwen reranker
python evaluation/offline_eval.py \
    --mode full \
    --retrieval_method lrurec \
    --retrieval_top_k 200 \
    --rerank_method qwen \
    --rerank_top_k 50 \
    --rerank_mode retrieval \
    --split test

# Evaluate full pipeline vá»›i Qwen3-VL (raw_image mode)
python evaluation/offline_eval.py \
    --mode full \
    --retrieval_method lrurec \
    --retrieval_top_k 200 \
    --rerank_method qwen3vl \
    --qwen3vl_mode raw_image \
    --rerank_top_k 50 \
    --rerank_mode retrieval \
    --split val

# Evaluate full pipeline vá»›i Qwen3-VL (caption mode)
python evaluation/offline_eval.py \
    --mode full \
    --retrieval_method lrurec \
    --retrieval_top_k 200 \
    --rerank_method qwen3vl \
    --qwen3vl_mode caption \
    --rerank_top_k 50 \
    --rerank_mode retrieval \
    --split test

# Evaluate full pipeline vá»›i Qwen3-VL (semantic_summary mode)
python evaluation/offline_eval.py \
    --mode full \
    --retrieval_method lrurec \
    --retrieval_top_k 200 \
    --rerank_method qwen3vl \
    --qwen3vl_mode semantic_summary \
    --rerank_top_k 50 \
    --rerank_mode retrieval \
    --split val

# Evaluate full pipeline vá»›i Qwen3-VL (semantic_summary_small mode)
python evaluation/offline_eval.py \
    --mode full \
    --retrieval_method lrurec \
    --retrieval_top_k 200 \
    --rerank_method qwen3vl \
    --qwen3vl_mode semantic_summary_small \
    --rerank_top_k 50 \
    --rerank_mode retrieval \
    --split test

# Evaluate rerank only (ground truth + negatives)
python evaluation/offline_eval.py \
    --mode rerank_only \
    --retrieval_method lrurec \
    --retrieval_top_k 200 \
    --rerank_method qwen \
    --rerank_top_k 50 \
    --split val
```

**Output format**: Táº¥t cáº£ metrics Ä‘Æ°á»£c hiá»ƒn thá»‹ dáº¡ng báº£ng vá»›i @5, @10, @20:
```
Metric       @5        @10        @20
Recall     0.1234    0.2345    0.3456
Ndcg       0.0567    0.0890    0.1234
Hit        0.4500    0.6700    0.8900
```

## ğŸ“ CÃ¡c Methods Available

### Retrieval Methods (Stage 1)
- `lrurec`: Neural LRU-based sequential recommender
- `mmgcn`: Multimodal Graph Convolutional Network (requires CLIP embeddings)
- `vbpr`: Visual Bayesian Personalized Ranking (requires CLIP image embeddings)
- `bm3`: Bootstrap Latent Representations for Multi-modal Recommendation (requires CLIP embeddings)

### Rerank Methods (Stage 2)
- `qwen`: Qwen LLM-based reranker (text-only)
- `qwen3vl`: Qwen3-VL reranker with 4 prompt modes:
  - `raw_image`: Use raw images directly in prompt
  - `caption`: Use image captions
  - `semantic_summary`: Use semantic summaries with Qwen3-VL
  - `semantic_summary_small`: Use semantic summaries with smaller model (Qwen3-0.6B)
- `vip5`: VIP5 multimodal T5-based reranker
- `bert4rec`: BERT4Rec sequential reranker

### Rerank Modes
- `retrieval`: Use candidates from Stage 1 (default)
- `ground_truth`: Use ground truth + 19 random negatives (for rerank quality evaluation)

### Training Modes
- **End-to-end**: Train cáº£ retrieval vÃ  rerank cÃ¹ng lÃºc (`train_pipeline.py`)
- **Standalone rerank**: Train rerank riÃªng láº», khÃ´ng cáº§n train retrieval (`train_rerank_standalone.py`)
  - `ground_truth` mode: KhÃ´ng cáº§n retrieval model
  - `retrieval` mode: Cáº§n load retrieval model Ä‘Ã£ train sáºµn

## âš™ï¸ Configuration

CÃ¡c hyperparameters cÃ³ thá»ƒ Ä‘iá»u chá»‰nh trong `config.py`:

### Retrieval Hyperparameters
- `--retrieval_epochs`: Sá»‘ epochs cho retrieval training (default: 10)
- `--retrieval_lr`: Learning rate cho retrieval methods (default: 1e-3)
- `--batch_size_retrieval`: Batch size cho retrieval training (default: 128)
- `--retrieval_patience`: Early stopping patience (default: 5)

### Rerank Hyperparameters
- `--rerank_epochs`: Sá»‘ epochs cho rerank training (default: 10)
- `--rerank_lr`: Learning rate cho rerank methods (default: 1e-4)
- `--rerank_batch_size`: Batch size cho rerank training (default: 32)
- `--rerank_patience`: Early stopping patience (default: 5)

### Reranker-Specific Config
- `--qwen_max_candidates`: Max candidates cho Qwen reranker (None = dÃ¹ng táº¥t cáº£ tá»« retrieval)
- `--qwen3vl_mode`: Prompt mode cho Qwen3-VL reranker (raw_image, caption, semantic_summary, semantic_summary_small)

### Performance Optimization Config
- `--semantic_summary_batch_size`: Batch size cho semantic summary generation (default: 4, cÃ³ thá»ƒ tÄƒng lÃªn 8, 16, 32 náº¿u GPU memory cho phÃ©p)
- `--use_quantization`: Sá»­ dá»¥ng 4-bit quantization cho models (tiáº¿t kiá»‡m memory, tÄƒng tá»‘c)
- `--use_torch_compile`: Sá»­ dá»¥ng torch.compile() Ä‘á»ƒ compile models (tÄƒng tá»‘c inference, cáº§n PyTorch 2.0+)

## ğŸ“Š Output

### Preprocessed Data
`data/preprocessed/{dataset_code}_min_rating{min_rating}-min_uc{min_uc}-min_sc{min_sc}/`
- `dataset_single_export.csv`: Dataset vá»›i captions vÃ  semantic summaries
- `clip_embeddings.pt`: CLIP embeddings (náº¿u cÃ³)
- `blip2_captions.pt`: BLIP2 captions cache (náº¿u cÃ³)
- `qwen3vl_semantic_summaries.pt`: Qwen3-VL semantic summaries cache (náº¿u cÃ³)

### Retrieval Results
`experiments/retrieval/{method}/{dataset_code}/seed{seed}/`
- `retrieved.csv`: Retrieved candidates
- `retrieved_metrics.json`: Evaluation metrics vá»›i @5, @10, @20

### Evaluation Results
Táº¥t cáº£ evaluation tá»± Ä‘á»™ng tÃ­nh vÃ  hiá»ƒn thá»‹ metrics cho @5, @10, @20:
- **Recall@K**: Tá»· lá»‡ relevant items Ä‘Æ°á»£c retrieve trong top-K
- **NDCG@K**: Normalized Discounted Cumulative Gain táº¡i K
- **Hit@K**: Tá»· lá»‡ users cÃ³ Ã­t nháº¥t 1 relevant item trong top-K

Output format:
```
Metric       @5        @10        @20
Recall     0.1234    0.2345    0.3456
Ndcg       0.0567    0.0890    0.1234
Hit        0.4500    0.6700    0.8900
```

## ğŸ’¡ Tips

1. **Training Ä‘á»™c láº­p**: 
   - Sá»­ dá»¥ng `train_rerank_standalone.py` Ä‘á»ƒ train rerank riÃªng láº», khÃ´ng cáº§n train retrieval
   - Ground truth mode khÃ´ng cáº§n retrieval model
   - Retrieval mode cáº§n load retrieval model Ä‘Ã£ train sáºµn

2. **Qwen reranker**: 
   - Sá»‘ lÆ°á»£ng candidates tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh theo `retrieval_top_k`
   - CÃ³ thá»ƒ giá»›i háº¡n báº±ng `--qwen_max_candidates` trong config.py

3. **CLIP embeddings**: 
   - Cáº§n cháº¡y `data_prepare.py` vá»›i `--use_image` hoáº·c `--use_text` trÆ°á»›c khi train MMGCN/VBPR/BM3

4. **Caption/Semantic Summary**: 
   - Cáº§n cháº¡y `data_prepare.py` vá»›i `--generate_caption` hoáº·c `--generate_semantic_summary` Ä‘á»ƒ generate
   - Captions cáº§n cho Qwen3-VL `caption` mode
   - Semantic summaries cáº§n cho Qwen3-VL `semantic_summary` vÃ  `semantic_summary_small` modes

5. **Image Resize**: 
   - Táº¥t cáº£ images Ä‘Æ°á»£c tá»± Ä‘á»™ng resize vá» max 448px trÃªn cáº¡nh dÃ i hÆ¡n (giá»¯ nguyÃªn aspect ratio)
   - GiÃºp tiáº¿t kiá»‡m memory vÃ  tÄƒng tá»‘c xá»­ lÃ½
   - Ãp dá»¥ng cho cáº£ training vÃ  inference

6. **Ground truth mode**: 
   - DÃ¹ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ rerank quality Ä‘á»™c láº­p vá»›i retrieval quality
   - Táº¡o candidates = [ground_truth] + 19 random negatives

7. **Evaluation metrics**: 
   - Táº¥t cáº£ evaluation tá»± Ä‘á»™ng tÃ­nh @5, @10, @20
   - Metrics: Recall, NDCG, Hit Rate
   - CÃ³ thá»ƒ evaluate trÃªn cáº£ val vÃ  test sets (dÃ¹ng `--split val` hoáº·c `--split test`)

8. **Qwen3-VL Training**: 
   - Táº¥t cáº£ 4 modes Ä‘á»u há»— trá»£ training: `raw_image`, `caption`, `semantic_summary`, `semantic_summary_small`
   - `raw_image` mode sá»­ dá»¥ng raw images trá»±c tiáº¿p cho cáº£ training vÃ  inference
   - Training sá»­ dá»¥ng per-epoch validation vá»›i early stopping
   - Xem chi tiáº¿t trong `QWEN3VL_TRAINING_REPORT.md`

## âš¡ Performance Optimization

### TÄƒng tá»‘c Semantic Summary Generation

```bash
# TÄƒng batch size (náº¿u GPU memory cho phÃ©p)
python data_prepare.py \
    --dataset_code beauty \
    --use_image \
    --generate_semantic_summary \
    --semantic_summary_batch_size 8  # TÄƒng tá»« 4 lÃªn 8

# Sá»­ dá»¥ng quantization Ä‘á»ƒ tiáº¿t kiá»‡m memory
python data_prepare.py \
    --dataset_code beauty \
    --use_image \
    --generate_semantic_summary \
    --use_quantization  # 4-bit quantization

# Sá»­ dá»¥ng torch.compile() Ä‘á»ƒ tÄƒng tá»‘c (PyTorch 2.0+)
python data_prepare.py \
    --dataset_code beauty \
    --use_image \
    --generate_semantic_summary \
    --use_torch_compile
```

### TÄƒng tá»‘c LLM Inference

```bash
# Sá»­ dá»¥ng torch.compile() cho LLM inference
python scripts/train_pipeline.py \
    --rerank_method qwen \
    --use_torch_compile  # Compile model Ä‘á»ƒ tÄƒng tá»‘c

# Sá»­ dá»¥ng quantization (Ä‘Ã£ cÃ³ sáºµn trong Unsloth)
# Model Ä‘Ã£ Ä‘Æ°á»£c load vá»›i 4-bit quantization máº·c Ä‘á»‹nh
```

**Expected Speedup**:
- `--semantic_summary_batch_size 8`: 2-4x faster
- `--use_quantization`: 1.5-2x faster, -50% memory
- `--use_torch_compile`: 1.2-1.5x faster

Xem chi tiáº¿t trong `OPTIMIZATION_GUIDE.md`.

## ğŸ”§ Troubleshooting

- **Qwen3-VL khÃ´ng load Ä‘Æ°á»£c**: Cáº§n cÃ i transformers tá»« source:
  ```bash
  pip install git+https://github.com/huggingface/transformers
  ```

- **CLIP embeddings khÃ´ng tÃ¬m tháº¥y**: Cháº¡y `data_prepare.py` vá»›i `--use_image` hoáº·c `--use_text` trÆ°á»›c.

- **Out of memory**: 
  - Giáº£m `--batch_size_retrieval` hoáº·c `--rerank_batch_size` trong `config.py`
  - Vá»›i Qwen3-VL `raw_image` mode: giáº£m batch size xuá»‘ng 4-8
  - Images Ä‘Ã£ Ä‘Æ°á»£c tá»± Ä‘á»™ng resize vá» 448px Ä‘á»ƒ tiáº¿t kiá»‡m memory
  - Sá»­ dá»¥ng `--use_quantization` Ä‘á»ƒ giáº£m memory usage

- **Qwen3-VL training cháº­m**: 
  - Sá»­ dá»¥ng `semantic_summary_small` mode (nháº¹ hÆ¡n, nhanh hÆ¡n)
  - Giáº£m batch size hoáº·c sá»‘ lÆ°á»£ng training samples
  - Sá»­ dá»¥ng GPU vá»›i Ä‘á»§ memory (recommended: 12GB+ cho VL modes)
  - Sá»­ dá»¥ng `--use_torch_compile` Ä‘á»ƒ tÄƒng tá»‘c

- **Semantic summary generation cháº­m**:
  - TÄƒng `--semantic_summary_batch_size` náº¿u GPU memory cho phÃ©p (8, 16, 32)
  - Sá»­ dá»¥ng `--use_quantization` Ä‘á»ƒ giáº£m memory vÃ  tÄƒng tá»‘c
  - Sá»­ dá»¥ng `--use_torch_compile` Ä‘á»ƒ compile model

- **LLM inference cháº­m**:
  - Sá»­ dá»¥ng `--use_torch_compile` Ä‘á»ƒ compile model
  - Model Ä‘Ã£ Ä‘Æ°á»£c load vá»›i 4-bit quantization máº·c Ä‘á»‹nh (Unsloth)
  - CÃ³ thá»ƒ batch multiple prompts náº¿u cáº§n (xem OPTIMIZATION_GUIDE.md)

- **Evaluation khÃ´ng cháº¡y Ä‘Æ°á»£c**: 
  - Kiá»ƒm tra xem Ä‘Ã£ train model chÆ°a
  - Äáº£m báº£o dataset Ä‘Ã£ Ä‘Æ°á»£c prepare vá»›i Ä‘Ãºng flags (--use_image, --generate_caption, etc.)
  - Kiá»ƒm tra `--qwen3vl_mode` cÃ³ Ä‘Ãºng vá»›i mode Ä‘Ã£ train khÃ´ng

