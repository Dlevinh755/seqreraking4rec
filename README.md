# Sequential Reranking for Recommendation

Há»‡ thá»‘ng recommendation hai giai Ä‘oáº¡n (Two-Stage): **Retrieval (Stage 1)** + **Reranking (Stage 2)** vá»›i há»— trá»£ multimodal (images, text, captions).

## ğŸ“‹ Tá»•ng quan

Pipeline recommendation hai giai Ä‘oáº¡n:
- **Stage 1 (Retrieval)**: Generate candidates tá»« toÃ n bá»™ item pool
- **Stage 2 (Reranking)**: Re-rank candidates tá»« Stage 1 Ä‘á»ƒ táº¡o final recommendations

### âœ¨ TÃ­nh nÄƒng chÃ­nh

- âœ… **4 Retrieval methods**: LRURec, MMGCN, VBPR, BM3
- âœ… **5 Rerank methods**: Qwen (LLM), Qwen3-VL (MLLM, 4 modes), VIP5, BERT4Rec
- âœ… **Multimodal support**: Images, text, captions (BLIP2), semantic summaries (Qwen3-VL)
- âœ… **Training Ä‘á»™c láº­p**: CÃ³ thá»ƒ train tá»«ng stage riÃªng hoáº·c end-to-end
- âœ… **Evaluation metrics**: Recall@K, NDCG@K, Hit@K táº¡i @5, @10, @20
- âœ… **Early stopping**: Per-epoch validation vá»›i early stopping

## ğŸ“¦ CÃ i Ä‘áº·t

```bash
# CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt

# CÃ i Ä‘áº·t transformers tá»« source (cáº§n cho Qwen3-VL)
pip install git+https://github.com/huggingface/transformers
```

## ğŸš€ Quick Start

### BÆ°á»›c 1: Prepare Data

```bash
# Basic (chá»‰ ratings)
python data_prepare.py \
    --dataset_code beauty \
    --min_rating 3 \
    --min_uc 20 \
    --min_sc 20

# Vá»›i images vÃ  text (cho MMGCN, VBPR, BM3)
python data_prepare.py \
    --dataset_code beauty \
    --min_rating 3 \
    --min_uc 20 \
    --min_sc 20 \
    --use_image \
    --use_text

# Vá»›i captions (cho Qwen3-VL caption mode)
python data_prepare.py \
    --dataset_code beauty \
    --min_rating 3 \
    --min_uc 20 \
    --min_sc 20 \
    --use_image \
    --generate_caption

# Vá»›i semantic summaries (cho Qwen3-VL semantic_summary mode)
python data_prepare.py \
    --dataset_code beauty \
    --min_rating 3 \
    --min_uc 20 \
    --min_sc 20 \
    --use_image \
    --generate_semantic_summary
```

### BÆ°á»›c 2: Train Retrieval (Stage 1)

```bash
# LRURec (khÃ´ng cáº§n images/text)
python scripts/train_retrieval.py --retrieval_method lrurec

# MMGCN (cáº§n images/text)
python scripts/train_retrieval.py --retrieval_method mmgcn

# VBPR (cáº§n images)
python scripts/train_retrieval.py --retrieval_method vbpr

# BM3 (cáº§n images + text)
python scripts/train_retrieval.py --retrieval_method bm3
```

### BÆ°á»›c 3: Train Rerank (Stage 2)

#### Standalone (khÃ´ng cáº§n retrieval model)

```bash
# Qwen LLM (text-only)
python scripts/train_rerank_standalone.py \
    --rerank_method qwen \
    --mode ground_truth

# Qwen3-VL (multimodal, 4 modes)
python scripts/train_rerank_standalone.py \
    --rerank_method qwen3vl \
    --mode ground_truth \
    --qwen3vl_mode raw_image  # hoáº·c: caption, semantic_summary, semantic_summary_small

# VIP5 (multimodal T5)
python scripts/train_rerank_standalone.py \
    --rerank_method vip5 \
    --mode ground_truth

# BERT4Rec (sequential)
python scripts/train_rerank_standalone.py \
    --rerank_method bert4rec \
    --mode ground_truth
```

#### Vá»›i Retrieval Model (Full Pipeline)

```bash
python scripts/train_rerank_standalone.py \
    --rerank_method qwen \
    --mode retrieval \
    --retrieval_method lrurec \
    --retrieval_top_k 200 \
    --rerank_top_k 50
```

### BÆ°á»›c 4: Train End-to-End (Stage 1 + Stage 2)

```bash
python scripts/train_pipeline.py \
    --retrieval_method lrurec \
    --retrieval_top_k 200 \
    --rerank_method qwen \
    --rerank_top_k 50 \
    --rerank_mode retrieval
```

## ğŸ“Š Methods Available

### Retrieval Methods (Stage 1)

| Method | Description | Requirements | Command |
|--------|-------------|-------------|---------|
| `lrurec` | Neural LRU-based sequential | Dataset cÆ¡ báº£n | `--retrieval_method lrurec` |
| `mmgcn` | Multimodal Graph Convolutional Network | Images/text + CLIP | `--retrieval_method mmgcn` |
| `vbpr` | Visual Bayesian Personalized Ranking | Images + CLIP | `--retrieval_method vbpr` |
| `bm3` | Bootstrap Latent Representations | Images + text + CLIP | `--retrieval_method bm3` |

### Rerank Methods (Stage 2)

| Method | Description | Requirements | Command |
|--------|-------------|-------------|---------|
| `qwen` | Qwen LLM (text-only) | Text data | `--rerank_method qwen` |
| `qwen3vl` | Qwen3-VL (multimodal, 4 modes) | TÃ¹y mode | `--rerank_method qwen3vl --qwen3vl_mode <mode>` |
| `vip5` | VIP5 multimodal T5 | Images + CLIP | `--rerank_method vip5` |
| `bert4rec` | BERT4Rec sequential | Sequential data | `--rerank_method bert4rec` |

### Qwen3-VL Modes

| Mode | Description | Data Preparation |
|------|-------------|------------------|
| `raw_image` | Raw images trong prompt | `--use_image` |
| `caption` | Image captions (BLIP2) | `--use_image --generate_caption` |
| `semantic_summary` | Semantic summaries (Qwen3-VL) | `--use_image --generate_semantic_summary` |
| `semantic_summary_small` | Semantic summaries (smaller model) | `--use_image --generate_semantic_summary` |

### Rerank Modes

| Mode | Description | Use Case |
|------|-------------|----------|
| `retrieval` | DÃ¹ng candidates tá»« Stage 1 | Full pipeline evaluation |
| `ground_truth` | GT + 19 random negatives | Rerank quality evaluation (independent) |

## âš™ï¸ Configuration

CÃ¡c hyperparameters cÃ³ thá»ƒ Ä‘iá»u chá»‰nh trong `config.py` hoáº·c command-line:

### Retrieval
- `--retrieval_epochs`: Sá»‘ epochs (default: 100)
- `--retrieval_lr`: Learning rate (default: 1e-4)
- `--batch_size_retrieval`: Batch size (default: 512)
- `--retrieval_patience`: Early stopping patience (default: 10)

### Rerank
- `--rerank_epochs`: Sá»‘ epochs (default: 10)
- `--rerank_lr`: Learning rate (default: 1e-4)
- `--rerank_batch_size`: Batch size (default: 32)
- `--rerank_patience`: Early stopping patience (default: 5)

### Qwen3-VL
- `--qwen3vl_mode`: Prompt mode (`raw_image`, `caption`, `semantic_summary`, `semantic_summary_small`)
- `--semantic_summary_batch_size`: Batch size cho summary generation (default: 4)

### Performance
- `--use_quantization`: 4-bit quantization (tiáº¿t kiá»‡m memory)
- `--use_torch_compile`: torch.compile() optimization (tÄƒng tá»‘c)

## ğŸ“ Output Structure

```
data/preprocessed/{dataset_code}_min_rating{min_rating}-min_uc{min_uc}-min_sc{min_sc}/
â”œâ”€â”€ dataset_single_export.csv      # Dataset vá»›i metadata
â”œâ”€â”€ clip_embeddings.pt              # CLIP embeddings (náº¿u cÃ³)
â”œâ”€â”€ blip2_captions.pt               # BLIP2 captions cache (náº¿u cÃ³)
â””â”€â”€ qwen3vl_semantic_summaries.pt   # Semantic summaries cache (náº¿u cÃ³)

experiments/
â”œâ”€â”€ retrieval/{method}/{dataset_code}/seed{seed}/
â”‚   â”œâ”€â”€ retrieved.csv               # Retrieved candidates
â”‚   â””â”€â”€ retrieved_metrics.json     # Evaluation metrics
â””â”€â”€ rerank/{method}/{dataset_code}/seed{seed}/
    â”œâ”€â”€ model.pt                    # Trained model
    â””â”€â”€ metrics.json                 # Evaluation metrics
```

## ğŸ“ˆ Evaluation Metrics

Táº¥t cáº£ evaluation tá»± Ä‘á»™ng tÃ­nh **Recall@K**, **NDCG@K**, **Hit@K** táº¡i **@5, @10, @20**:

```
Metric       @5        @10        @20
Recall     0.1234    0.2345    0.3456
Ndcg       0.0567    0.0890    0.1234
Hit        0.4500    0.6700    0.8900
```

## ğŸ’¡ Important Notes

1. **Data Preparation Order**:
   - Cháº¡y `data_prepare.py` vá»›i Ä‘Ãºng flags trÆ°á»›c khi train
   - MMGCN/VBPR/BM3 cáº§n `--use_image` hoáº·c `--use_text`
   - Qwen3-VL caption mode cáº§n `--generate_caption`
   - Qwen3-VL semantic_summary mode cáº§n `--generate_semantic_summary`

2. **Training Modes**:
   - **Standalone**: Train tá»«ng stage riÃªng (`train_retrieval.py`, `train_rerank_standalone.py`)
   - **End-to-end**: Train cáº£ 2 stages (`train_pipeline.py`)

3. **Ground Truth Mode**:
   - DÃ¹ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ rerank quality Ä‘á»™c láº­p vá»›i retrieval
   - Táº¡o candidates = [ground_truth] + 19 random negatives
   - KhÃ´ng cáº§n retrieval model

4. **CLIP Embeddings**:
   - Tá»± Ä‘á»™ng extract khi cháº¡y `data_prepare.py` vá»›i `--use_image` hoáº·c `--use_text`
   - Cáº§n cho MMGCN, VBPR, BM3, VIP5

5. **Image Processing**:
   - Tá»± Ä‘á»™ng resize vá» 224Ã—224 (giá»¯ aspect ratio)
   - Tiáº¿t kiá»‡m memory vÃ  tÄƒng tá»‘c xá»­ lÃ½

## ğŸ”§ Troubleshooting

- **Qwen3-VL khÃ´ng load**: CÃ i transformers tá»« source: `pip install git+https://github.com/huggingface/transformers`
- **Out of memory**: Giáº£m batch size trong `config.py` hoáº·c dÃ¹ng `--use_quantization`
- **CLIP embeddings khÃ´ng tÃ¬m tháº¥y**: Cháº¡y `data_prepare.py` vá»›i `--use_image` hoáº·c `--use_text`

## ğŸ“š Cáº¥u trÃºc Project

```
seqreraking4rec/
â”œâ”€â”€ config.py                    # Main configuration
â”œâ”€â”€ data_prepare.py              # Data preprocessing
â”œâ”€â”€ dataset/                     # Dataset modules
â”‚   â”œâ”€â”€ base.py                  # Base dataset class
â”‚   â”œâ”€â”€ beauty.py                # Amazon Beauty
â”‚   â”œâ”€â”€ games.py                 # Video Games
â”‚   â””â”€â”€ ml_100k.py               # MovieLens
â”œâ”€â”€ retrieval/                   # Stage 1: Retrieval
â”‚   â”œâ”€â”€ base.py                  # BaseRetriever interface
â”‚   â”œâ”€â”€ methods/                  # Retrieval methods
â”‚   â””â”€â”€ models/                  # PyTorch models
â”œâ”€â”€ rerank/                      # Stage 2: Reranking
â”‚   â”œâ”€â”€ base.py                  # BaseReranker interface
â”‚   â”œâ”€â”€ methods/                  # Rerank methods
â”‚   â””â”€â”€ models/                  # PyTorch models
â””â”€â”€ scripts/                     # Training scripts
    â”œâ”€â”€ train_retrieval.py        # Train retrieval only
    â”œâ”€â”€ train_rerank_standalone.py # Train rerank only
    â””â”€â”€ train_pipeline.py         # Train end-to-end
```

## ğŸ“ License

[Add your license here]
